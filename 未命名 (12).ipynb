{
 "cells": [
  {
   "id": "9e4c9e8a2c56bb3f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# config env\n",
    "pkgs_path = \"/bohr/pkgs-7x29/v5/pkgs\"\n",
    "llava_lib_path = \"/bohr/libb-bg5b/v3/llava\"\n",
    "tsr_model_path = \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "model_path = \"lmms-lab/llava-onevision-qwen2-7b-si\"\n",
    "cache_path = \"/bohr/cach-rxl3/v3/cache\"\n",
    "\n",
    "# pkgs_path = \"/personal/pkgs\"\n",
    "# llava_lib_path = \"/personal/llava\"\n",
    "# model_path = \"lmms-lab/llava-onevision-qwen2-0.5b-ov\"\n",
    "# cache_path = \"/personal/cache\"\n",
    "\n",
    "# !pip install {pkgs_path}/*\n",
    "!cp {llava_lib_path} . -r\n",
    "import os\n",
    "\n",
    "# # 提交时可能不能联网，设置成离线模式防止联网失败报错\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_path\n",
    "os.environ[\"HF_HOME\"] = cache_path\n",
    "device = \"cuda\""
   ],
   "execution_count": 1,
   "outputs": [
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_6",
     "output_type": "execute_reply",
     "data": {
      "status": "ok",
      "execution_count": 1,
      "user_expressions": {},
      "payload": []
     },
     "meta": {
      "started": "2024-08-25T12:27:13.034053Z",
      "dependencies_met": true,
      "engine": "22b159d0-aaa9-4dbb-a070-d6e77e44386d",
      "status": "ok"
     },
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_6",
      "msg_type": "execute_reply",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:13.710307Z",
      "version": "5.3"
     }
    }
   ]
  },
  {
   "id": "664dfe51317d5d0f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from llava.conversation import Conversation, SeparatorStyle\n",
    "from llava.utils import disable_torch_init\n",
    "import json\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import process_images, tokenizer_image_token\n",
    "from llava.constants import IMAGE_TOKEN_INDEX\n",
    "import torch\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoImageProcessor, TableTransformerForObjectDetection\n",
    "from llava.constants import DEFAULT_IMAGE_TOKEN\n",
    "import multiprocessing\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_10",
     "output_type": "stream",
     "name": "stderr",
     "text": "/opt/mamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n",
     "data": {
      "name": "stderr",
      "text": "/opt/mamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
     },
     "meta": {},
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_10",
      "msg_type": "stream",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:15.666279Z",
      "version": "5.3"
     }
    },
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_11",
     "output_type": "execute_reply",
     "data": {
      "status": "ok",
      "execution_count": 2,
      "user_expressions": {},
      "payload": []
     },
     "meta": {
      "started": "2024-08-25T12:27:13.713570Z",
      "dependencies_met": true,
      "engine": "22b159d0-aaa9-4dbb-a070-d6e77e44386d",
      "status": "ok"
     },
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_11",
      "msg_type": "execute_reply",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:18.721739Z",
      "version": "5.3"
     }
    }
   ]
  },
  {
   "id": "89f8307aac1c3988",
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T11:57:07.389264Z",
     "start_time": "2024-08-07T11:57:07.273027Z"
    }
   },
   "source": [
    "\n",
    "args = type('Args', (), {\n",
    "    \"conv_mode\": None,\n",
    "    \"sep\": \",\",\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1,\n",
    "    \"num_beams\": 1,\n",
    "    \"max_new_tokens\": 4096\n",
    "})()\n",
    "\n",
    "l2i = defaultdict(lambda: -1)\n",
    "for i, letter in enumerate('ABCDEFGH'):\n",
    "    l2i[letter] = i\n",
    "sub_list = ('Physics', 'Mathematics', 'ComputerScience', 'QuantitativeBiology', 'QuantitativeFinance',\n",
    "            'Statistics', 'ElectricalEngineeringandSystemsScience', 'Economics', '')\n",
    "torch.cuda.empty_cache()\n",
    "disable_torch_init()\n",
    "\n",
    "if os.environ.get('DATA_PATH_B'):  # 提交时会选择隐藏的测试数据集路径（A+B榜），数据集的格式与A榜数据相同，但数目不同（5360张）\n",
    "    base_dir = os.environ.get('DATA_PATH_B')\n",
    "else:\n",
    "    base_dir = '/bohr/form-recognition-train-b6y2/v4'  # 示例，把A榜测试数据集路径作为测试集路径，仅开发时挂载A榜数据用于debug   # 示例，把A榜测试数据集路径作为测试集路径，仅开发时挂载A榜数据用于debug"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_15",
     "output_type": "execute_reply",
     "data": {
      "status": "ok",
      "execution_count": 3,
      "user_expressions": {},
      "payload": []
     },
     "meta": {
      "started": "2024-08-25T12:27:18.724066Z",
      "dependencies_met": true,
      "engine": "22b159d0-aaa9-4dbb-a070-d6e77e44386d",
      "status": "ok"
     },
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_15",
      "msg_type": "execute_reply",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:18.728099Z",
      "version": "5.3"
     }
    }
   ]
  },
  {
   "id": "3b21a43f-6086-4da8-857c-5db5ce2ef37a",
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def count_rows_cols(latex_code):\n",
    "    try:\n",
    "        # 查找列数：根据表格行的定义找到表格列标识符，如 |l|c|c|c|c|\n",
    "        columns = re.search(r'\\\\begin\\{tabular\\}\\{([^\\}]+)\\}', latex_code)\n",
    "        if columns:\n",
    "            num_cols = len([c for c in columns.group(1) if c.isalpha()])\n",
    "        else:\n",
    "            num_cols = 0\n",
    "\n",
    "        # 查找行数：根据 \\hline 分隔符统计表格的行数\n",
    "        rows = latex_code.split(r'\\hline')\n",
    "        num_rows = sum(1 for row in rows if '&' in row or '\\\\rule' in row)\n",
    "\n",
    "        return num_rows, num_cols\n",
    "    except:\n",
    "        return -1, -1\n",
    "    \n",
    "\n",
    "def clean_out(image_path, outputs):\n",
    "    pattern = r'{.*}'\n",
    "\n",
    "    # Find the JSON string using the pattern\n",
    "    match = re.search(pattern, outputs, re.DOTALL)\n",
    "    sub_item = {\n",
    "        \"image_path\": image_path,\n",
    "        \"category\": \"\",\n",
    "        \"cols\": -1,\n",
    "        \"rows\": -1,\n",
    "        \"answer\": -1,\n",
    "    }\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            # Parse the JSON string into a Python dictionary\n",
    "            data = json.loads(json_str)\n",
    "            rows, cols = count_rows_cols(data[\"LaTex\"])\n",
    "            sub_item = {\n",
    "                \"image_path\": image_path,\n",
    "                \"category\": sub_list[l2i[data[\"subject\"][0]]],\n",
    "                \"cols\": cols,\n",
    "                \"rows\": rows,\n",
    "                \"answer\": l2i[data[\"option\"][0]],\n",
    "            }\n",
    "        except:\n",
    "            return sub_item\n",
    "    else:\n",
    "        return sub_item\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_19",
     "output_type": "execute_reply",
     "data": {
      "status": "ok",
      "execution_count": 4,
      "user_expressions": {},
      "payload": []
     },
     "meta": {
      "started": "2024-08-25T12:27:18.730425Z",
      "dependencies_met": true,
      "engine": "22b159d0-aaa9-4dbb-a070-d6e77e44386d",
      "status": "ok"
     },
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_19",
      "msg_type": "execute_reply",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:18.735247Z",
      "version": "5.3"
     }
    }
   ]
  },
  {
   "id": "ce8b4d4174b19252",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Worker:\n",
    "    def __init__(self):\n",
    "        with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "            # self.data = list(json.load(f))[:2]\n",
    "        self.main_input = multiprocessing.Queue()\n",
    "\n",
    "    def run(self):\n",
    "        tsr_process = multiprocessing.Process(target=self.tsr_process)\n",
    "        tsr_process.start()\n",
    "        self.main_process()\n",
    "\n",
    "    def tsr_process(self):\n",
    "        tsr_img_processor = AutoImageProcessor.from_pretrained(tsr_model_path)\n",
    "        tsr_img_processor.size = {'height': 384, 'width': 384}\n",
    "        tsr_model = TableTransformerForObjectDetection.from_pretrained(tsr_model_path)\n",
    "        label2id = tsr_model.config.label2id\n",
    "        label_row = label2id['table row']\n",
    "        label_col = label2id['table column']\n",
    "        for item in self.data:\n",
    "            path = os.path.join(base_dir, 'test_images', item[\"image_path\"])\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "            inputs = tsr_img_processor(images=image, return_tensors=\"pt\")\n",
    "            outputs = tsr_model(**inputs)\n",
    "\n",
    "            target_sizes = torch.tensor([image.size[::-1]])  # (height, width) of each image in the batch\n",
    "            results = \\\n",
    "                tsr_img_processor.post_process_object_detection(outputs, threshold=0.6, target_sizes=target_sizes)[0]\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            rows = 0\n",
    "            cols = 0\n",
    "            for label, box in zip(results[\"labels\"], results[\"boxes\"]):\n",
    "                label, box = label.item(), box.tolist()\n",
    "                draw.rectangle(box, outline=\"red\", width=1)\n",
    "                if label == label_row:\n",
    "                    rows += 1\n",
    "                elif label == label_col:\n",
    "                    cols += 1\n",
    "            self.main_input.put((image, rows, cols, item))\n",
    "\n",
    "        self.main_input.put(None)\n",
    "\n",
    "    def main_process(self):\n",
    "        tokenizer, model, image_processor, _ = load_pretrained_model(\n",
    "            model_path, None, \"llava_qwen\", device_map=\"auto\",\n",
    "            attn_implementation='sdpa',\n",
    "            # load_8bit=True,\n",
    "            # load_4bit=False,\n",
    "            **{\n",
    "                \"multimodal\": True,\n",
    "                \"overwrite_config\": {\n",
    "                    \"image_aspect_ratio\": \"anyres_max_9\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        submission = []\n",
    "        while True:\n",
    "            item = self.main_input.get()\n",
    "            # print(\"MAIN ITEM\", item)\n",
    "            if item is None:\n",
    "                break\n",
    "\n",
    "            image, rows, cols, item = item\n",
    "            image_sizes = [image.size]\n",
    "            images = [image]\n",
    "            image_tensors = [\n",
    "                process_images(images, image_processor, model.config)[0].to(dtype=torch.float16, device=device)]\n",
    "            latex = r'\\begin{tabular}{|c|c|c|} \\hline 1 & 2 & 3 \\\\ \\hline 4 & 5 & 6 \\\\ \\hline \\end{tabular}'\n",
    "            qs = f\"\"\"{DEFAULT_IMAGE_TOKEN}\\n This is a table image with red borders. The caption of the table is \"{item[\"caption\"]}\". Following are three tasks:\n",
    "1. Convert this table to LaTex.\n",
    "2. Based on the provided table, caption and LaTex, select the most relevant subject to the table from (A. Physics, B. Mathematics, C. ComputerScience, D. QuantitativeBiology, E. QuantitativeFinance, F. Statistics, G. ElectricalEngineeringandSystemsScience, H. Economics).\n",
    "3. Based on the provided table, caption and LaTex, for the question: \"{item[\"question\"]}\", select the most correct option from (A. {item[\"options\"][0]}, B. {item[\"options\"][1]}, C. {item[\"options\"][2]}, D. {item[\"options\"][3]}).\n",
    "- Answer in the Json format. Example: `{\n",
    "            \"LaTex\": \"{latex}\",\n",
    "  \"subject\": \"B\",\n",
    "  \"option\": \"C\"\n",
    "}`\"\"\"\n",
    "            conv = Conversation(\n",
    "                system=\"\"\"<|im_start|>system\n",
    "                    You are a helpful assistant.\"\"\",\n",
    "                roles=[\"<|im_start|>user\", \"<|im_start|>assistant\"],\n",
    "                version=\"qwen\",\n",
    "                messages=[],\n",
    "                offset=0,\n",
    "                sep_style=SeparatorStyle.CHATML,\n",
    "                sep=\"<|im_end|>\",\n",
    "            )\n",
    "            conv.append_message(conv.roles[0], qs)\n",
    "            conv.append_message(conv.roles[1], None)\n",
    "            prompt = conv.get_prompt()\n",
    "            input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(\n",
    "                0).cuda()\n",
    "            print(prompt)\n",
    "            output_ids = model.generate(\n",
    "                input_ids,\n",
    "                images=image_tensors,\n",
    "                image_sizes=image_sizes,\n",
    "                do_sample=True if args.temperature > 0 else False,\n",
    "                temperature=args.temperature,\n",
    "                top_p=args.top_p,\n",
    "                num_beams=args.num_beams,\n",
    "                max_new_tokens=args.max_new_tokens,\n",
    "                use_cache=True,\n",
    "            )\n",
    "            outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "            sub_item = clean_out(item[\"image_path\"], outputs)\n",
    "            # print(\"MAIN\", rows, cols)\n",
    "            # print(\"MAIN:\", out_list)\n",
    "            print(outputs)\n",
    "            print(\"MAIN\", sub_item)\n",
    "            image.show()\n",
    "            submission.append(sub_item)\n",
    "        with open('submission.json', 'w') as f:\n",
    "            json.dump(submission, f)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_23",
     "output_type": "execute_reply",
     "data": {
      "status": "ok",
      "execution_count": 5,
      "user_expressions": {},
      "payload": []
     },
     "meta": {
      "started": "2024-08-25T12:27:18.737004Z",
      "dependencies_met": true,
      "engine": "22b159d0-aaa9-4dbb-a070-d6e77e44386d",
      "status": "ok"
     },
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_23",
      "msg_type": "execute_reply",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:18.750520Z",
      "version": "5.3"
     }
    }
   ]
  },
  {
   "id": "c1b896614c8ead1f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "worker = Worker()\n",
    "worker.run()"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_27",
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded LLaVA model: lmms-lab/llava-onevision-qwen2-7b-si\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nYou are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.\nOverwriting config with {'image_aspect_ratio': 'anyres_max_9'}\nLoading vision tower: google/siglip-so400m-patch14-384\nLoading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.40s/it]\nModel Class: LlavaQwenForCausalLM\n<|im_start|>system\n                    You are a helpful assistant.<|im_end|>\n<|im_start|>user\n<image>\n This is a table image with red borders. The caption of the table is \"Finding the MD4-39 preimages for 500 randomly generated 128-bit Boolean vectors. Instances with preimages are satisfiable, while those with no preimages are unsatisfiable.\". Following are three tasks:\n            1. Convert this table to LaTex.\n            2. Based on the provided table, caption and LaTex, select the most relevant subject to the table from (A. Physics, B. Mathematics, C. ComputerScience, D. QuantitativeBiology, E. QuantitativeFinance, F. Statistics, G. ElectricalEngineeringandSystemsScience, H. Economics).\n            3. Based on the provided table, caption and LaTex, for the question: \"What is the maximum solving time for the relaxation constraint $\\rho_1$?\", select the most correct option from (A. 46 seconds, B. 250 seconds, C. 80 seconds, D. 12 seconds).\n            For the tasks, answer in the format: [LaTex, subject, option]. Example of a valid answer: [\\begin{tabular}{|c|c|c|} \\hline 1 & 2 & 3 \\\\ \\hline 4 & 5 & 6 \\\\ \\hline \\end{tabular}, A, B]\n            <|im_end|>\n<|im_start|>assistant\n\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
     "data": {
      "name": "stdout",
      "text": "Loaded LLaVA model: lmms-lab/llava-onevision-qwen2-7b-si\n"
     },
     "meta": {},
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_27",
      "msg_type": "stream",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:19.119964Z",
      "version": "5.3"
     }
    },
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_42",
     "output_type": "error",
     "data": {
      "traceback": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
       "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m worker \u001B[38;5;241m=\u001B[39m Worker()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "Cell \u001B[0;32mIn[5], line 11\u001B[0m, in \u001B[0;36mWorker.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      9\u001B[0m tsr_process \u001B[38;5;241m=\u001B[39m multiprocessing\u001B[38;5;241m.\u001B[39mProcess(target\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtsr_process)\n\u001B[1;32m     10\u001B[0m tsr_process\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "Cell \u001B[0;32mIn[5], line 103\u001B[0m, in \u001B[0;36mWorker.main_process\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     91\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     92\u001B[0m     input_ids,\n\u001B[1;32m     93\u001B[0m     images\u001B[38;5;241m=\u001B[39mimage_tensors,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    100\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    101\u001B[0m )\n\u001B[1;32m    102\u001B[0m outputs \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(output_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m--> 103\u001B[0m sub_item \u001B[38;5;241m=\u001B[39m \u001B[43mclean_out\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimage_path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# print(\"MAIN\", rows, cols)\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;66;03m# print(\"MAIN:\", out_list)\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28mprint\u001B[39m(outputs)\n",
       "Cell \u001B[0;32mIn[4], line 10\u001B[0m, in \u001B[0;36mclean_out\u001B[0;34m(image_path, outputs)\u001B[0m\n\u001B[1;32m      8\u001B[0m category \u001B[38;5;241m=\u001B[39m content[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      9\u001B[0m answer \u001B[38;5;241m=\u001B[39m content[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 10\u001B[0m rows, cols \u001B[38;5;241m=\u001B[39m \u001B[43mcount_rows_cols\u001B[49m(latex_table)\n\u001B[1;32m     11\u001B[0m sub_item \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_path\u001B[39m\u001B[38;5;124m\"\u001B[39m: image_path,\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m\"\u001B[39m: sub_list[l2i[category]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m: l2i[answer],\n\u001B[1;32m     17\u001B[0m }\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sub_item\n",
       "\u001B[0;31mNameError\u001B[0m: name 'count_rows_cols' is not defined"
      ],
      "ename": "NameError",
      "evalue": "name 'count_rows_cols' is not defined"
     },
     "meta": {},
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_42",
      "msg_type": "error",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:40.212973Z",
      "version": "5.3"
     },
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m worker \u001B[38;5;241m=\u001B[39m Worker()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 11\u001B[0m, in \u001B[0;36mWorker.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      9\u001B[0m tsr_process \u001B[38;5;241m=\u001B[39m multiprocessing\u001B[38;5;241m.\u001B[39mProcess(target\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtsr_process)\n\u001B[1;32m     10\u001B[0m tsr_process\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 103\u001B[0m, in \u001B[0;36mWorker.main_process\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     91\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     92\u001B[0m     input_ids,\n\u001B[1;32m     93\u001B[0m     images\u001B[38;5;241m=\u001B[39mimage_tensors,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    100\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    101\u001B[0m )\n\u001B[1;32m    102\u001B[0m outputs \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(output_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m--> 103\u001B[0m sub_item \u001B[38;5;241m=\u001B[39m \u001B[43mclean_out\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimage_path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# print(\"MAIN\", rows, cols)\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;66;03m# print(\"MAIN:\", out_list)\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28mprint\u001B[39m(outputs)\n",
      "Cell \u001B[0;32mIn[4], line 10\u001B[0m, in \u001B[0;36mclean_out\u001B[0;34m(image_path, outputs)\u001B[0m\n\u001B[1;32m      8\u001B[0m category \u001B[38;5;241m=\u001B[39m content[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      9\u001B[0m answer \u001B[38;5;241m=\u001B[39m content[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 10\u001B[0m rows, cols \u001B[38;5;241m=\u001B[39m \u001B[43mcount_rows_cols\u001B[49m(latex_table)\n\u001B[1;32m     11\u001B[0m sub_item \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_path\u001B[39m\u001B[38;5;124m\"\u001B[39m: image_path,\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m\"\u001B[39m: sub_list[l2i[category]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m: l2i[answer],\n\u001B[1;32m     17\u001B[0m }\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sub_item\n",
      "\u001B[0;31mNameError\u001B[0m: name 'count_rows_cols' is not defined"
     ]
    },
    {
     "id": "476e4705-276518f7f668c0cf4ac06a18_193_43",
     "output_type": "execute_reply",
     "data": {
      "status": "error",
      "traceback": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
       "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m worker \u001B[38;5;241m=\u001B[39m Worker()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "Cell \u001B[0;32mIn[5], line 11\u001B[0m, in \u001B[0;36mWorker.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      9\u001B[0m tsr_process \u001B[38;5;241m=\u001B[39m multiprocessing\u001B[38;5;241m.\u001B[39mProcess(target\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtsr_process)\n\u001B[1;32m     10\u001B[0m tsr_process\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "Cell \u001B[0;32mIn[5], line 103\u001B[0m, in \u001B[0;36mWorker.main_process\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     91\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     92\u001B[0m     input_ids,\n\u001B[1;32m     93\u001B[0m     images\u001B[38;5;241m=\u001B[39mimage_tensors,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    100\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    101\u001B[0m )\n\u001B[1;32m    102\u001B[0m outputs \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(output_ids, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m--> 103\u001B[0m sub_item \u001B[38;5;241m=\u001B[39m \u001B[43mclean_out\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimage_path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# print(\"MAIN\", rows, cols)\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;66;03m# print(\"MAIN:\", out_list)\u001B[39;00m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28mprint\u001B[39m(outputs)\n",
       "Cell \u001B[0;32mIn[4], line 10\u001B[0m, in \u001B[0;36mclean_out\u001B[0;34m(image_path, outputs)\u001B[0m\n\u001B[1;32m      8\u001B[0m category \u001B[38;5;241m=\u001B[39m content[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      9\u001B[0m answer \u001B[38;5;241m=\u001B[39m content[\u001B[38;5;241m2\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 10\u001B[0m rows, cols \u001B[38;5;241m=\u001B[39m \u001B[43mcount_rows_cols\u001B[49m(latex_table)\n\u001B[1;32m     11\u001B[0m sub_item \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_path\u001B[39m\u001B[38;5;124m\"\u001B[39m: image_path,\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m\"\u001B[39m: sub_list[l2i[category]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m: l2i[answer],\n\u001B[1;32m     17\u001B[0m }\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sub_item\n",
       "\u001B[0;31mNameError\u001B[0m: name 'count_rows_cols' is not defined"
      ],
      "ename": "NameError",
      "evalue": "name 'count_rows_cols' is not defined",
      "engine_info": {
       "engine_uuid": "22b159d0-aaa9-4dbb-a070-d6e77e44386d",
       "engine_id": -1,
       "method": "execute"
      },
      "execution_count": 6,
      "user_expressions": {},
      "payload": []
     },
     "meta": {
      "started": "2024-08-25T12:27:18.752145Z",
      "dependencies_met": true,
      "engine": "22b159d0-aaa9-4dbb-a070-d6e77e44386d",
      "status": "error"
     },
     "parent_header": {
      "msg_id": "476e4705-276518f7f668c0cf4ac06a18_193_43",
      "msg_type": "execute_reply",
      "username": "username",
      "session": "476e4705-276518f7f668c0cf4ac06a18",
      "date": "2024-08-25T12:27:40.215164Z",
      "version": "5.3"
     }
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
