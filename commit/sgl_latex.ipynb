{
 "cells": [
  {
   "id": "9e4c9e8a2c56bb3f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pkgs_path = \"/bohr/pkgs-7x29/v15/pkgs\"\n",
    "# llava_lib_path = \"/bohr/libb-bg5b/v3/llava\"\n",
    "# tsr_model_path = \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "model_path = \"lmms-lab/llava-onevision-qwen2-7b-si\"\n",
    "cache_path = \"/bohr/cach-rxl3/v9/cache\"\n",
    "\n",
    "# pkgs_path = \"/personal/pkgs\"\n",
    "# llava_lib_path = \"/personal/llava\"\n",
    "# model_path = \"lmms-lab/llava-onevision-qwen2-0.5b-ov\"\n",
    "# cache_path = \"/personal/cache\"\n",
    "\n",
    "!pip install {pkgs_path}/* --ignore-installed\n",
    "\n",
    "import os\n",
    "\n",
    "# os.system(f\"pip install {pkgs_path}/* --ignore-installed\")\n",
    "# os.system(f\"cp -r {llava_lib_path} .\")\n",
    "# # 提交时可能不能联网，设置成离线模式防止联网失败报错\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_path\n",
    "os.environ[\"HF_HOME\"] = cache_path\n",
    "device = \"cuda\"\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "id": "664dfe51317d5d0f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import json\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "from sglang.lang.chat_template import get_chat_template\n",
    "from sglang.srt.server import launch_server\n",
    "from sglang.srt.server_args import ServerArgs\n",
    "from sglang.srt.utils import allocate_init_ports\n",
    "\n",
    "from sglang import RuntimeEndpoint\n",
    "import warnings\n",
    "import sglang as sgl\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "id": "3b21a43f-6086-4da8-857c-5db5ce2ef37a",
   "cell_type": "code",
   "metadata": {},
   "source": [
    "l2i = defaultdict(lambda: -1)\n",
    "for i, letter in enumerate('ABCDEFGH'):\n",
    "    l2i[letter] = i\n",
    "sub_list = ('Physics', 'Mathematics', 'ComputerScience', 'QuantitativeBiology', 'QuantitativeFinance',\n",
    "            'Statistics', 'ElectricalEngineeringandSystemsScience', 'Economics', '')\n",
    "torch.cuda.empty_cache()\n",
    "# disable_torch_init()\n",
    "\n",
    "if os.environ.get('DATA_PATH_B'):  # 提交时会选择隐藏的测试数据集路径（A+B榜），数据集的格式与A榜数据相同，但数目不同（5360张）\n",
    "    base_dir = os.environ.get('DATA_PATH_B')\n",
    "else:\n",
    "    base_dir = '/bohr/form-recognition-train-b6y2/v4'  # 示例，把A榜测试数据集路径作为测试集路径，仅开发时挂载A榜数据用于debug   # 示例，把A榜测试数据集路径作为测试集路径，仅开发时挂载A榜数据用于debug"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "id": "7d60f859a5c4cd7f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Runtime(sgl.srt.server.Runtime):\n",
    "    def __init__(\n",
    "            self,\n",
    "            log_level: str = \"error\",\n",
    "            model_overide_args: Optional[dict] = None,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \"\"\"See the arguments in server_args.py::ServerArgs\"\"\"\n",
    "        self.server_args = ServerArgs(*args, log_level=log_level, **kwargs)\n",
    "\n",
    "        # Pre-allocate ports\n",
    "        self.server_args.port, self.server_args.additional_ports = allocate_init_ports(\n",
    "            self.server_args.port,\n",
    "            self.server_args.additional_ports,\n",
    "            self.server_args.dp_size,\n",
    "        )\n",
    "\n",
    "        self.url = self.server_args.url()\n",
    "        self.generate_url = (\n",
    "            f\"http://{self.server_args.host}:{self.server_args.port}/generate\"\n",
    "        )\n",
    "\n",
    "        self.pid = None\n",
    "        # logger.info(\"Launching server...\")\n",
    "        pipe_reader, pipe_writer = mp.Pipe(duplex=False)\n",
    "        proc = mp.Process(\n",
    "            target=launch_server,\n",
    "            args=(self.server_args, model_overide_args, pipe_writer),\n",
    "        )\n",
    "        # logger.info(\"Waiting for server to launch...\")\n",
    "        proc.start()\n",
    "        self.pid = proc.pid\n",
    "        # logger.info(\"Waiting for server to launch...\")\n",
    "        # pipe_writer.close()\n",
    "        # timeout = 60\n",
    "        # import time\n",
    "        # start_time = time.time()\n",
    "        #\n",
    "        # while True:\n",
    "        #     logger.info(\"Waiting for initialization state...\", flush=True)\n",
    "        #     if pipe_reader.poll(timeout=1):\n",
    "        #         logger.info(\"Waiting for initialization state...\", flush=True)\n",
    "        #         init_state = pipe_reader.recv()\n",
    "        #         break\n",
    "        #     if time.time() - start_time > timeout:\n",
    "        #         raise TimeoutError(\"Timeout while waiting for initialization state\")\n",
    "        # try:\n",
    "        #     init_state = pipe_reader.recv()\n",
    "        # except EOFError:\n",
    "        #     init_state = \"\"\n",
    "        init_state = pipe_reader.recv()\n",
    "\n",
    "        if init_state != \"init ok\":\n",
    "            self.shutdown()\n",
    "            raise RuntimeError(\n",
    "                \"Initialization failed. Please see the error messages above.\"\n",
    "            )\n",
    "        self.endpoint = RuntimeEndpoint(self.url)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "id": "490ec8f770a62d7e",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "@sgl.function\n",
    "def one_image(s, img_path, caption, q3):\n",
    "    img_path = os.path.join(base_dir, 'test_images', img_path)\n",
    "    s += sgl.user(\n",
    "        sgl.image(img_path) +\n",
    "        f'This is a table image. The caption of the table is \"{caption}\".')\n",
    "    s += sgl.assistant(\"I have a general understanding of the information in this table.\")\n",
    "    s += sgl.user(\"Convert this table to LaTex.\")\n",
    "    s += sgl.assistant(sgl.gen(\"LaTex\", max_tokens=4096, temperature=0.0, top_p=1))\n",
    "    s += sgl.user(\n",
    "        \"Based on the provided table, caption and LaTex, select the most relevant subject to the table from (A. Physics, B. Mathematics, C. ComputerScience, D. QuantitativeBiology, E. QuantitativeFinance, F. Statistics, G. ElectricalEngineeringandSystemsScience, H. Economics). Answer with the option's letter from the given choices directly.\")\n",
    "    s += sgl.assistant(\n",
    "        sgl.gen(\"subject\", choices=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"],\n",
    "                max_tokens=2, temperature=0.0, top_p=1))\n",
    "    s += sgl.user(q3)\n",
    "    s += sgl.assistant(sgl.gen(\"option\", choices=[\"A\", \"B\", \"C\", \"D\"], max_tokens=2, temperature=0.0, top_p=1))\n",
    "\n",
    "\n",
    "def count_rows_cols(latex_code):\n",
    "    try:\n",
    "        # 查找列数：根据表格行的定义找到表格列标识符，如 |l|c|c|c|c|\n",
    "        columns = re.search(r'\\\\begin\\{tabular\\}\\{([^\\}]+)\\}', latex_code)\n",
    "        if columns:\n",
    "            num_cols = len([c for c in columns.group(1) if c.isalpha()])\n",
    "        else:\n",
    "            num_cols = 0\n",
    "\n",
    "        # 查找行数：根据 \\hline 分隔符统计表格的行数\n",
    "        rows = latex_code.split(r'\\hline')\n",
    "        num_rows = sum(1 for row in rows if '&' in row or '\\\\rule' in row)\n",
    "\n",
    "        return num_rows, num_cols\n",
    "    except:\n",
    "        return -1, -1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "id": "ce8b4d4174b19252",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Worker:\n",
    "\n",
    "    def __init__(self):\n",
    "        with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.batch_size = 4\n",
    "        self.submission = []\n",
    "\n",
    "    def run(self):\n",
    "        model_overide_args = {\n",
    "            \"attn_implementation\": \"eager\",\n",
    "            \"multimodal\": True,\n",
    "            \"overwrite_config\": {\n",
    "                \"image_aspect_ratio\": \"anyres_max_9\"\n",
    "            }\n",
    "        }\n",
    "        runtime = Runtime(\n",
    "            model_path=model_path,\n",
    "            model_overide_args=model_overide_args,\n",
    "        )\n",
    "        runtime.endpoint.chat_template = get_chat_template(\"qwen\")\n",
    "        sgl.set_default_backend(runtime)\n",
    "        self.process()\n",
    "\n",
    "    def process(self):\n",
    "        batch_images = []\n",
    "        for item in self.data:\n",
    "            q3 = f\"\"\"Based on the provided table, caption and LaTex, for the question: \"{item[\"question\"]}\", select the most correct option from (A. {item[\"options\"][0]}, B. {item[\"options\"][1]}, C. {item[\"options\"][2]}, D. {item[\"options\"][3]}). Answer with the option\\'s letter from the given choices directly.\"\"\"\n",
    "            # batch_images.append((item[\"image_path\"], item[\"caption\"], q3))\n",
    "            batch_images.append({\n",
    "                \"img_path\": item[\"image_path\"],\n",
    "                \"caption\": item[\"caption\"],\n",
    "                \"q3\": q3\n",
    "            })\n",
    "            if len(batch_images) == self.batch_size:\n",
    "                self.batch(batch_images)\n",
    "                batch_images = []\n",
    "        with open('submission.json', 'w') as f:\n",
    "            json.dump(self.submission, f)\n",
    "\n",
    "    def batch(self, batch_images):\n",
    "        states = one_image.run_batch(batch_images)\n",
    "        for i, s in enumerate(states):\n",
    "            self.clean_out(batch_images[i][\"img_path\"], s)\n",
    "\n",
    "    def clean_out(self, img_path, s):\n",
    "        try:\n",
    "            latex = s[\"LaTex\"]\n",
    "            rows, cols = count_rows_cols(latex)\n",
    "        except:\n",
    "            rows, cols = -1, -1\n",
    "        try:\n",
    "            category = sub_list[l2i[s[\"subject\"][0]]]\n",
    "        except:\n",
    "            category = \"\"\n",
    "        try:\n",
    "            answer = l2i[s[\"option\"][0]]\n",
    "        except:\n",
    "            answer = -1\n",
    "        sub_item = {\n",
    "            \"image_path\": img_path,\n",
    "            \"category\": category,\n",
    "            \"cols\": cols,\n",
    "            \"rows\": rows,\n",
    "            \"answer\": answer,\n",
    "        }\n",
    "        self.submission.append(sub_item)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "id": "c1b896614c8ead1f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "worker = Worker()\n",
    "worker.run()"
   ],
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
