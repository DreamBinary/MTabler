{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "\n",
    "q_prefix = \"Based on the table, caption and html structure, \"\n",
    "NEW_IMG_DIR = \"new_images\"\n",
    "os.makedirs(NEW_IMG_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def rewrite():\n",
    "    if os.environ.get('DATA_PATH_B'):\n",
    "        base_dir = os.environ.get('DATA_PATH_B')\n",
    "    else:\n",
    "        base_dir = '/bohr/form-recognition-train-b6y2/v4'\n",
    "    with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "        data_t = json.load(f)\n",
    "        # data_t = list(data_t)[:10]\n",
    "        # write path to json\n",
    "    # new_data = []\n",
    "    data = []\n",
    "    for d in data_t:\n",
    "        r_path = os.path.join(base_dir, \"test_images\", d[\"image_path\"])\n",
    "        w_path = os.path.join(NEW_IMG_DIR, d[\"image_path\"])\n",
    "        # image = Image.open(path).convert(\"RGB\")\n",
    "        question = d[\"question\"]\n",
    "        question = question[0].lower() + question[1:]\n",
    "        q3 = f\"\"\"{q_prefix}{question}\n",
    "A) {d[\"options\"][0]}\n",
    "B) {d[\"options\"][1]}\n",
    "C) {d[\"options\"][2]}\n",
    "D) {d[\"options\"][3]}\n",
    "\"\"\"\n",
    "        data.append({\n",
    "            \"r_path\": r_path,\n",
    "            \"w_path\": w_path,\n",
    "            \"image_path\": d[\"image_path\"],\n",
    "            \"caption\": d[\"caption\"],\n",
    "            # \"image\": image,\n",
    "            \"q3\": q3,\n",
    "        })\n",
    "\n",
    "    with open('data.json', 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# import logging\n",
    "# \n",
    "# multiprocessing.log_to_stderr(logging.INFO)\n",
    "# logger = multiprocessing.get_logger()\n",
    "# logging.basicConfig(filename='sgl_unitable4.log', level=logging.INFO)\n",
    "\n",
    "p = multiprocessing.Process(target=rewrite)\n",
    "p.start()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6516b14bf2dc4d7e"
  },
  {
   "id": "9e4c9e8a2c56bb3f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pkgs_path = \"/bohr/pkgs-7x29/v18/pkgs\"\n",
    "model_path = \"lmms-lab/llava-onevision-qwen2-7b-si\"\n",
    "cache_path = \"/bohr/cach-rxl3/v9/cache\"\n",
    "# pkgs_path = \"/personal/pkgs\"\n",
    "# llava_lib_path = \"/personal/llava\"\n",
    "# model_path = \"lmms-lab/llava-onevision-qwen2-0.5b-ov\"\n",
    "# cache_path = \"/personal/cache\"\n",
    "OCR_BASE_DIR = \"/bohr/ocrr-zlwd/v2/OCRCache\"\n",
    "\n",
    "os.system(f\"pip3 install {pkgs_path}/* --ignore-installed\")\n",
    "# os.system(f\"cp -r {llava_lib_path} .\")\n",
    "# # 提交时可能不能联网，设置成离线模式防止联网失败报错\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_path\n",
    "os.environ[\"HF_HOME\"] = cache_path\n",
    "device = \"cuda\"\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "id": "664dfe51317d5d0f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from collections import defaultdict\n",
    "from sglang import Runtime\n",
    "from sglang.lang.chat_template import get_chat_template\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr.paddleocr import parse_args\n",
    "from paddleocr.ppstructure.table.predict_table import TableSystem\n",
    "import warnings\n",
    "import sglang as sgl\n",
    "import torch\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "id": "3b21a43f-6086-4da8-857c-5db5ce2ef37a",
   "cell_type": "code",
   "metadata": {},
   "source": [
    "l2i = defaultdict(lambda: -1)\n",
    "for i, letter in enumerate('ABCDEFGH'):\n",
    "    l2i[letter] = i\n",
    "sub_list = ('Physics', 'Mathematics', 'ComputerScience', 'QuantitativeBiology', 'QuantitativeFinance',\n",
    "            'Statistics', 'ElectricalEngineeringandSystemsScience', 'Economics', '')\n",
    "torch.cuda.empty_cache()\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "id": "490ec8f770a62d7e",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# def count_rows_and_columns(html_tags):\n",
    "#     rows = 0\n",
    "#     max_columns = 0\n",
    "#     current_columns = 0\n",
    "#     rowspan_columns = {}\n",
    "#     index = 0\n",
    "#     columns_cnt = defaultdict(int)\n",
    "#     while index < len(html_tags):\n",
    "#         tag = html_tags[index]\n",
    "# \n",
    "#         if tag == '<tr>':\n",
    "#             rows += 1\n",
    "#             current_columns = 0\n",
    "# \n",
    "#             # Account for any ongoing rowspans from previous rows\n",
    "#             for col, span in rowspan_columns.items():\n",
    "#                 if span > 1:\n",
    "#                     current_columns += 1\n",
    "#                     rowspan_columns[col] -= 1\n",
    "# \n",
    "#         elif tag.startswith('<td'):\n",
    "#             colspan = 1\n",
    "#             rowspan = 1\n",
    "# \n",
    "#             # Check if 'colspan' and 'rowspan' are in the subsequent strings\n",
    "#             if index + 1 < len(html_tags) and 'colspan=\"' in html_tags[index + 1]:\n",
    "#                 colspan = int(html_tags[index + 1].strip().split('colspan=\"')[1].split('\"')[0])\n",
    "#                 index += 1  # Skip the colspan string\n",
    "#             if index + 1 < len(html_tags) and 'rowspan=\"' in html_tags[index + 1]:\n",
    "#                 rowspan = int(html_tags[index + 1].strip().split('rowspan=\"')[1].split('\"')[0])\n",
    "#                 index += 1  # Skip the rowspan string\n",
    "# \n",
    "#             # Increment columns count\n",
    "#             current_columns += colspan\n",
    "# \n",
    "#             # Track rowspans for subsequent rows\n",
    "#             if rowspan > 1:\n",
    "#                 for _ in range(colspan):\n",
    "#                     rowspan_columns[current_columns - _] = rowspan\n",
    "# \n",
    "#         elif tag == '</tr>':\n",
    "#             print(f\"Row {rows} has {current_columns} columns\")\n",
    "#             columns_cnt[current_columns] += 1\n",
    "#             max_columns = max(max_columns, current_columns)\n",
    "# \n",
    "#         index += 1\n",
    "#     columns = max(columns_cnt, key=columns_cnt.get)\n",
    "#     return rows, columns"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# class Runtime(sgl.srt.server.Runtime):\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             log_level: str = \"error\",\n",
    "#             model_overide_args: Optional[dict] = None,\n",
    "#             *args,\n",
    "#             **kwargs,\n",
    "#     ):\n",
    "#         \"\"\"See the arguments in server_args.py::ServerArgs\"\"\"\n",
    "#         self.server_args = ServerArgs(*args, log_level=log_level, **kwargs)\n",
    "# \n",
    "#         # Pre-allocate ports\n",
    "#         self.server_args.port, self.server_args.additional_ports = allocate_init_ports(\n",
    "#             self.server_args.port,\n",
    "#             self.server_args.additional_ports,\n",
    "#             self.server_args.dp_size,\n",
    "#         )\n",
    "# \n",
    "#         self.url = self.server_args.url()\n",
    "#         self.generate_url = (\n",
    "#             f\"http://{self.server_args.host}:{self.server_args.port}/generate\"\n",
    "#         )\n",
    "# \n",
    "#         self.pid = None\n",
    "#         # logger.info(\"Launching server...\")\n",
    "#         pipe_reader, pipe_writer = multiprocessing.Pipe(duplex=False)\n",
    "#         proc = multiprocessing.Process(\n",
    "#             target=launch_server,\n",
    "#             args=(self.server_args, model_overide_args, pipe_writer),\n",
    "#         )\n",
    "#         # logger.info(\"Waiting for server to launch...\")\n",
    "#         proc.start()\n",
    "#         self.pid = proc.pid\n",
    "#         # logger.info(\"Waiting for server to launch...\")\n",
    "#         # pipe_writer.close()\n",
    "#         # timeout = 60\n",
    "#         # import time\n",
    "#         # start_time = time.time()\n",
    "#         #\n",
    "#         # while True:\n",
    "#         #     logger.info(\"Waiting for initialization state...\", flush=True)\n",
    "#         #     if pipe_reader.poll(timeout=1):\n",
    "#         #         logger.info(\"Waiting for initialization state...\", flush=True)\n",
    "#         #         init_state = pipe_reader.recv()\n",
    "#         #         break\n",
    "#         #     if time.time() - start_time > timeout:\n",
    "#         #         raise TimeoutError(\"Timeout while waiting for initialization state\")\n",
    "#         # try:\n",
    "#         #     init_state = pipe_reader.recv()\n",
    "#         # except EOFError:\n",
    "#         #     init_state = \"\"\n",
    "#         init_state = pipe_reader.recv()\n",
    "# \n",
    "#         if init_state != \"init ok\":\n",
    "#             self.shutdown()\n",
    "#             raise RuntimeError(\n",
    "#                 \"Initialization failed. Please see the error messages above.\"\n",
    "#             )\n",
    "#         self.endpoint = RuntimeEndpoint(self.url)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd8bf6ce2f67763d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "q2 = f\"\"\"{q_prefix}which subject is most relevant to the table or caption?\n",
    "A) Physics\n",
    "B) Mathematics\n",
    "C) Computer Science\n",
    "D) Quantitative Biology\n",
    "E) Quantitative Finance\n",
    "F) Statistics\n",
    "G) Electrical Engineering and Systems Science\n",
    "H) Economics\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@sgl.function\n",
    "def one_image(s, path, q1, q3):\n",
    "    s += sgl.system(\n",
    "        \"You are a helpful assistant. Provide only an label ([A-H] or [A-D]) of the correct answer for multiple-choice questions.\")\n",
    "    # s += sgl.user(\n",
    "    #     sgl.image(img_path) +\n",
    "    #     f'This is a table image. The caption of the table is \"{caption}\". The OCR recognition result of the table in HTML format is {tsr}, which can be used as a reference but no standard answer')\n",
    "    s += sgl.user(sgl.image(path) + q1)\n",
    "    s += sgl.assistant(\"I have a general understanding of the information in this table.\")\n",
    "    s += sgl.user(q2)\n",
    "    s += sgl.assistant(\n",
    "        sgl.gen_string(\"subject\",\n",
    "                       # choices=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"],\n",
    "                       max_tokens=2, temperature=0.0, top_p=1\n",
    "                       ))\n",
    "    s += sgl.user(q3)\n",
    "    s += sgl.assistant(\n",
    "        sgl.gen_string(\"option\",\n",
    "                       # choices=[\"A\", \"B\", \"C\", \"D\"],\n",
    "                       max_tokens=2, temperature=0.0, top_p=1\n",
    "                       ))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eafee8947f97850"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class OCR(TableSystem):\n",
    "    def __init__(self, **kwargs):\n",
    "        params = parse_args(mMain=False)\n",
    "        params.__dict__.update(**kwargs)\n",
    "\n",
    "        params.structure_version = \"PP-StructureV2\"\n",
    "        params.use_gpu = False\n",
    "        params.mode = \"structure\"\n",
    "\n",
    "        params.table_max_len = 488\n",
    "        params.precision = \"fp32\"\n",
    "        params.enable_mkldnn = True\n",
    "        params.merge_no_span_structure = True\n",
    "        params.cpu_threads = 16\n",
    "\n",
    "        params.table_algorithm = \"SLANet\"\n",
    "\n",
    "        params.use_mp = True\n",
    "        params.total_process_num = 4\n",
    "\n",
    "        params.det_model_dir = os.path.join(OCR_BASE_DIR, \"whl\", \"det\", \"en\", \"en_PP-OCRv3_det_infer\")\n",
    "        params.rec_model_dir = os.path.join(OCR_BASE_DIR, \"whl\", \"rec\", \"en\", \"en_PP-OCRv4_rec_infer\")\n",
    "        params.table_model_dir = os.path.join(OCR_BASE_DIR, \"whl\", \"table\", \"en_ppstructure_mobile_v2.0_SLANet_infer\")\n",
    "        # params.layout_model_dir = os.path.join(BASE_DIR, \"whl\", \"layout\")\n",
    "\n",
    "        params.rec_char_dict_path = os.path.join(OCR_BASE_DIR, \"dict\", \"en_dict.txt\")\n",
    "        params.table_char_dict_path = os.path.join(OCR_BASE_DIR, \"dict\", \"table_structure_dict.txt\")\n",
    "        # params.layout_dict_path = os.path.join(BASE_DIR, \"dict\", \"layout_publaynet_dict.txt\")\n",
    "\n",
    "        super().__init__(params)\n",
    "\n",
    "    def run(self, img, path):\n",
    "        # result = dict()\n",
    "        structure_res, elapse = self._structure(copy.deepcopy(img))\n",
    "        # result[\"cell_bbox\"] = structure_res[1].tolist()\n",
    "        dt_boxes, rec_res, det_elapse, rec_elapse = self._ocr(copy.deepcopy(img))\n",
    "        # result[\"boxes\"] = [x.tolist() for x in dt_boxes]\n",
    "        boxes = [x.tolist() for x in dt_boxes]\n",
    "        # result[\"rec_res\"] = rec_res\n",
    "        # pred_html = self.match(structure_res, dt_boxes, rec_res)\n",
    "        # result[\"html\"] = pred_html\n",
    "        # print(boxes)\n",
    "        img = self.draw_bbox(img, boxes)\n",
    "        cv2.imwrite(path, img)\n",
    "        return structure_res[0]\n",
    "\n",
    "    def draw_bbox(self, img, boxes):\n",
    "        # img = copy.deepcopy(img)\n",
    "        boxes = np.array(boxes).astype(int)\n",
    "        for box in boxes:\n",
    "            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 1)\n",
    "        return img\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31c86174f7a7378"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clean_out(o, s):\n",
    "    img_path, rows, cols = o\n",
    "    category = \"\"\n",
    "    answer = -1\n",
    "    try:\n",
    "        subject = s[\"subject\"]\n",
    "        match = re.search(r'[A-Za-z]', subject)\n",
    "        if match:\n",
    "            category = match.group(0).upper()\n",
    "            category = sub_list[l2i[category]]\n",
    "    except:\n",
    "        category = \"\"\n",
    "    try:\n",
    "        option = s[\"option\"]\n",
    "        match = re.search(r'[A-Za-z]', option)\n",
    "        if match:\n",
    "            answer = match.group(0).upper()\n",
    "            answer = l2i[answer]\n",
    "    except:\n",
    "        answer = -1\n",
    "    sub_item = {\n",
    "        \"image_path\": img_path,\n",
    "        \"category\": category,\n",
    "        \"cols\": cols,\n",
    "        \"rows\": rows,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "    return sub_item"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e4dd940d9c81c22"
  },
  {
   "id": "ce8b4d4174b19252",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Worker:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 8\n",
    "        self.ocr_data = multiprocessing.Queue()\n",
    "        # self.result = multiprocessing.Queue()\n",
    "\n",
    "    def run(self):\n",
    "        ocr_process = multiprocessing.Process(target=self.ocr)\n",
    "        ocr_process.start()\n",
    "\n",
    "        model_overide_args = {\n",
    "            \"attn_implementation\": \"eager\",\n",
    "            \"multimodal\": True,\n",
    "            \"overwrite_config\": {\n",
    "                \"image_aspect_ratio\": \"anyres_max_9\"\n",
    "            }\n",
    "        }\n",
    "        runtime = Runtime(\n",
    "            model_path=model_path,\n",
    "            model_overide_args=model_overide_args,\n",
    "        )\n",
    "        runtime.endpoint.chat_template = get_chat_template(\"qwen\")\n",
    "        sgl.set_default_backend(runtime)\n",
    "\n",
    "        # post = multiprocessing.Process(target=self.post_process)\n",
    "        # post.start()\n",
    "\n",
    "        self.process()\n",
    "        runtime.shutdown()\n",
    "        # post.join()\n",
    "\n",
    "    def ocr(self):\n",
    "        engine = OCR(layout=False, show_log=False, lang=\"en\")\n",
    "        outputs = []\n",
    "        inputs = []\n",
    "        with open('data.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for item in data:\n",
    "            img = cv2.imread(item[\"r_path\"])\n",
    "            html = engine.run(img, item[\"w_path\"])\n",
    "            rows, cols = -1, -1\n",
    "            q1 = f'This is a table image marked with red recognized borders. The caption of the table is \"{item[\"caption\"]}\". The structure of the table in html format is as follows: {html}.'\n",
    "            outputs.append((item[\"image_path\"], rows, cols))\n",
    "            inputs.append({\"path\": item[\"w_path\"], \"q1\": q1, \"q3\": item[\"q3\"]})\n",
    "            if len(outputs) == self.batch_size:\n",
    "                self.ocr_data.put((outputs, inputs))\n",
    "                outputs, inputs = [], []\n",
    "        if outputs:\n",
    "            self.ocr_data.put((outputs, inputs))\n",
    "        self.ocr_data.put(None)\n",
    "\n",
    "    def process(self):\n",
    "        flag = True\n",
    "        submission = []\n",
    "        while flag:\n",
    "            item = self.ocr_data.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            outputs, inputs = item\n",
    "            states = one_image.run_batch(inputs)\n",
    "            for o, s in zip(outputs, states):\n",
    "                sub_item = clean_out(o, s)\n",
    "                submission.append(sub_item)\n",
    "        if len(submission) != 5360:\n",
    "            raise Exception(f\"Submission length is {len(submission)}\")\n",
    "        with open('submission.json', 'w') as f:\n",
    "            json.dump(submission, f)\n",
    "        #     self.result.put((outputs, results))\n",
    "        # self.result.put(None)\n",
    "\n",
    "    # def post_process(self):\n",
    "    #     submission = []\n",
    "    #     while True:\n",
    "    #         item = self.result.get()\n",
    "    #         if item is None:\n",
    "    #             break\n",
    "    #         outputs, states = item\n",
    "    #         for o, s in zip(outputs, states):\n",
    "    #             sub_item = clean_out(o, s)\n",
    "    #             submission.append(sub_item)\n",
    "    #     if len(submission) != 5360:\n",
    "    #         raise Exception(f\"Submission length is {len(submission)}\")\n",
    "    #     with open('submission.json', 'w') as f:\n",
    "    #         json.dump(submission, f)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "id": "c1b896614c8ead1f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "p.join()\n",
    "worker = Worker()\n",
    "worker.run()\n"
   ],
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
