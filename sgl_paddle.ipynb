{
 "cells": [
  {
   "id": "9e4c9e8a2c56bb3f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pkgs_path = \"/bohr/pkgs-7x29/v18/pkgs\"\n",
    "# llava_lib_path = \"/bohr/libb-bg5b/v3/llava\"\n",
    "# tsr_model_path = \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "model_path = \"lmms-lab/llava-onevision-qwen2-7b-si\"\n",
    "cache_path = \"/bohr/cach-rxl3/v9/cache\"\n",
    "table_model_dir = \"/bohr/ocrr-zlwd/v1/ch_ppstructure_openatom_SLANetv2_infer\"\n",
    "table_char_dict_path = \"/bohr/ocrr-zlwd/v1/table_structure_dict.txt\"\n",
    "# pkgs_path = \"/personal/pkgs\"\n",
    "# llava_lib_path = \"/personal/llava\"\n",
    "# model_path = \"lmms-lab/llava-onevision-qwen2-0.5b-ov\"\n",
    "# cache_path = \"/personal/cache\"\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.system(f\"pip install {pkgs_path}/* --ignore-installed\")\n",
    "# os.system(f\"cp -r {llava_lib_path} .\")\n",
    "# # 提交时可能不能联网，设置成离线模式防止联网失败报错\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_path\n",
    "os.environ[\"HF_HOME\"] = cache_path\n",
    "device = \"cuda\"\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "id": "664dfe51317d5d0f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import json\n",
    "import multiprocessing as mp\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "from sglang.lang.chat_template import get_chat_template\n",
    "from sglang.srt.server import launch_server\n",
    "from sglang.srt.server_args import ServerArgs\n",
    "from sglang.srt.utils import allocate_init_ports\n",
    "from sglang import RuntimeEndpoint\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr.ppocr.data.imaug import transform\n",
    "from paddleocr.ppstructure.table.predict_structure import TableStructurer\n",
    "\n",
    "import warnings\n",
    "import sglang as sgl\n",
    "import torch\n",
    "import multiprocessing\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "id": "3b21a43f-6086-4da8-857c-5db5ce2ef37a",
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "l2i = defaultdict(lambda: -1)\n",
    "for i, letter in enumerate('ABCDEFGH'):\n",
    "    l2i[letter] = i\n",
    "sub_list = ('Physics', 'Mathematics', 'ComputerScience', 'QuantitativeBiology', 'QuantitativeFinance',\n",
    "            'Statistics', 'ElectricalEngineeringandSystemsScience', 'Economics', '')\n",
    "torch.cuda.empty_cache()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "id": "7d60f859a5c4cd7f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Runtime(sgl.srt.server.Runtime):\n",
    "    def __init__(\n",
    "            self,\n",
    "            log_level: str = \"error\",\n",
    "            model_overide_args: Optional[dict] = None,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \"\"\"See the arguments in server_args.py::ServerArgs\"\"\"\n",
    "        self.server_args = ServerArgs(*args, log_level=log_level, **kwargs)\n",
    "\n",
    "        # Pre-allocate ports\n",
    "        self.server_args.port, self.server_args.additional_ports = allocate_init_ports(\n",
    "            self.server_args.port,\n",
    "            self.server_args.additional_ports,\n",
    "            self.server_args.dp_size,\n",
    "        )\n",
    "\n",
    "        self.url = self.server_args.url()\n",
    "        self.generate_url = (\n",
    "            f\"http://{self.server_args.host}:{self.server_args.port}/generate\"\n",
    "        )\n",
    "\n",
    "        self.pid = None\n",
    "        # logger.info(\"Launching server...\")\n",
    "        pipe_reader, pipe_writer = mp.Pipe(duplex=False)\n",
    "        proc = mp.Process(\n",
    "            target=launch_server,\n",
    "            args=(self.server_args, model_overide_args, pipe_writer),\n",
    "        )\n",
    "        # logger.info(\"Waiting for server to launch...\")\n",
    "        proc.start()\n",
    "        self.pid = proc.pid\n",
    "        # logger.info(\"Waiting for server to launch...\")\n",
    "        # pipe_writer.close()\n",
    "        # timeout = 60\n",
    "        # import time\n",
    "        # start_time = time.time()\n",
    "        #\n",
    "        # while True:\n",
    "        #     logger.info(\"Waiting for initialization state...\", flush=True)\n",
    "        #     if pipe_reader.poll(timeout=1):\n",
    "        #         logger.info(\"Waiting for initialization state...\", flush=True)\n",
    "        #         init_state = pipe_reader.recv()\n",
    "        #         break\n",
    "        #     if time.time() - start_time > timeout:\n",
    "        #         raise TimeoutError(\"Timeout while waiting for initialization state\")\n",
    "        # try:\n",
    "        #     init_state = pipe_reader.recv()\n",
    "        # except EOFError:\n",
    "        #     init_state = \"\"\n",
    "        init_state = pipe_reader.recv()\n",
    "\n",
    "        if init_state != \"init ok\":\n",
    "            self.shutdown()\n",
    "            raise RuntimeError(\n",
    "                \"Initialization failed. Please see the error messages above.\"\n",
    "            )\n",
    "        self.endpoint = RuntimeEndpoint(self.url)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TSR(TableStructurer):\n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        data = {\"image\": img}\n",
    "        data = transform(data, self.preprocess_op)\n",
    "        img = data[0]\n",
    "        if img is None:\n",
    "            return None, 0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = img.copy()\n",
    "        if self.use_onnx:\n",
    "            input_dict = {}\n",
    "            input_dict[self.input_tensor.name] = img\n",
    "            outputs = self.predictor.run(self.output_tensors, input_dict)\n",
    "        else:\n",
    "            self.input_tensor.copy_from_cpu(img)\n",
    "            self.predictor.run()\n",
    "            outputs = []\n",
    "            for output_tensor in self.output_tensors:\n",
    "                output = output_tensor.copy_to_cpu()\n",
    "                outputs.append(output)\n",
    "\n",
    "        preds = {}\n",
    "        preds[\"structure_probs\"] = outputs[1]\n",
    "        preds[\"loc_preds\"] = outputs[0]\n",
    "\n",
    "        shape_list = np.expand_dims(data[-1], axis=0)\n",
    "        post_result = self.postprocess_op(preds, [shape_list])\n",
    "\n",
    "        structure_str_list = post_result[\"structure_batch_list\"][0]\n",
    "        bbox_list = post_result[\"bbox_batch_list\"][0]\n",
    "        structure_str_list = structure_str_list[0]\n",
    "        # structure_str_list = (\n",
    "        #         [\"<html>\", \"<body>\", \"<table>\"]\n",
    "        #         + structure_str_list\n",
    "        #         + [\"</table>\", \"</body>\", \"</html>\"]\n",
    "        # )\\\n",
    "        structure_str_list = [\"<table>\"] + structure_str_list + [\"</table>\"]\n",
    "        return structure_str_list, bbox_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "926ffd3102503a4e"
  },
  {
   "id": "490ec8f770a62d7e",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def count_rows_and_columns(html_tags):\n",
    "    rows = 0\n",
    "    max_columns = 0\n",
    "    current_columns = 0\n",
    "    rowspan_columns = {}\n",
    "    index = 0\n",
    "    columns_cnt = defaultdict(int)\n",
    "    while index < len(html_tags):\n",
    "        tag = html_tags[index]\n",
    "\n",
    "        if tag == '<tr>':\n",
    "            rows += 1\n",
    "            current_columns = 0\n",
    "\n",
    "            # Account for any ongoing rowspans from previous rows\n",
    "            for col, span in rowspan_columns.items():\n",
    "                if span > 1:\n",
    "                    current_columns += 1\n",
    "                    rowspan_columns[col] -= 1\n",
    "\n",
    "        elif tag.startswith('<td'):\n",
    "            colspan = 1\n",
    "            rowspan = 1\n",
    "\n",
    "            # Check if 'colspan' and 'rowspan' are in the subsequent strings\n",
    "            if index + 1 < len(html_tags) and 'colspan=\"' in html_tags[index + 1]:\n",
    "                colspan = int(html_tags[index + 1].strip().split('colspan=\"')[1].split('\"')[0])\n",
    "                index += 1  # Skip the colspan string\n",
    "            if index + 1 < len(html_tags) and 'rowspan=\"' in html_tags[index + 1]:\n",
    "                rowspan = int(html_tags[index + 1].strip().split('rowspan=\"')[1].split('\"')[0])\n",
    "                index += 1  # Skip the rowspan string\n",
    "\n",
    "            # Increment columns count\n",
    "            current_columns += colspan\n",
    "\n",
    "            # Track rowspans for subsequent rows\n",
    "            if rowspan > 1:\n",
    "                for _ in range(colspan):\n",
    "                    rowspan_columns[current_columns - _] = rowspan\n",
    "\n",
    "        elif tag == '</tr>':\n",
    "            print(f\"Row {rows} has {current_columns} columns\")\n",
    "            columns_cnt[current_columns] += 1\n",
    "            max_columns = max(max_columns, current_columns)\n",
    "\n",
    "        index += 1\n",
    "    columns = max(columns_cnt, key=columns_cnt.get)\n",
    "    return rows, columns\n",
    "\n",
    "@sgl.function\n",
    "def one_image(s, img_path, caption, q3, tsr):\n",
    "    q2 = \"\"\"\n",
    "Based on the table, caption and html structure, which subject is most relevant to the table and caption?\n",
    "A) Physics\n",
    "B) Mathematics\n",
    "C) Computer Science\n",
    "D) Quantitative Biology\n",
    "E) Quantitative Finance\n",
    "F) Statistics\n",
    "G) Electrical Engineering and Systems Science\n",
    "H) Economics\n",
    "\"\"\"\n",
    "    s += sgl.system(\"You are a helpful assistant. Provide only an label ([A-H] or [A-D]) of the correct answer for multiple-choice questions.\")\n",
    "    s += sgl.user(\n",
    "        sgl.image(img_path) +\n",
    "        f'This is a table image. The caption of the table is \"{caption}\". The structure of the table in html format is as follows: {tsr}.')\n",
    "    s += sgl.assistant(\"I have a general understanding of the information in this table.\")\n",
    "    s += sgl.user(q2)\n",
    "    s += sgl.assistant(\n",
    "        sgl.gen(\"subject\",\n",
    "                # choices=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"],\n",
    "                max_tokens=2, temperature=0.0, top_p=1))\n",
    "    s += sgl.user(q3)\n",
    "    s += sgl.assistant(sgl.gen(\"option\",\n",
    "                               # choices=[\"A\", \"B\", \"C\", \"D\"],\n",
    "                               max_tokens=2, temperature=0.0, top_p=1))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "id": "ce8b4d4174b19252",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Worker:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 8\n",
    "        self.submission = []\n",
    "        self.ocr_data = multiprocessing.Queue()\n",
    "\n",
    "    def run(self):\n",
    "        ocr_process = multiprocessing.Process(target=self.ocr)\n",
    "        ocr_process.start()\n",
    "\n",
    "        model_overide_args = {\n",
    "            \"attn_implementation\": \"eager\",\n",
    "            \"multimodal\": True,\n",
    "            \"overwrite_config\": {\n",
    "                \"image_aspect_ratio\": \"anyres_max_9\"\n",
    "            }\n",
    "        }\n",
    "        runtime = Runtime(\n",
    "            model_path=model_path,\n",
    "            model_overide_args=model_overide_args,\n",
    "        )\n",
    "        runtime.endpoint.chat_template = get_chat_template(\"qwen\")\n",
    "        sgl.set_default_backend(runtime)\n",
    "        self.process()\n",
    "        runtime.shutdown()\n",
    "\n",
    "    def ocr(self):\n",
    "        args = type(\"Args\", (), {\n",
    "            \"table_model_dir\": table_model_dir,\n",
    "            \"table_char_dict_path\": table_char_dict_path,\n",
    "            \"use_gpu\": False,\n",
    "            # \"gpu_id\": 0,\n",
    "            # \"gpu_mem\": 500,\n",
    "            \"use_npu\": False,\n",
    "            \"use_mlu\": False,\n",
    "            \"use_xpu\": False,\n",
    "            \"precision\": \"fp32\",\n",
    "            \"benchmark\": False,\n",
    "            \"use_tensorrt\": False,\n",
    "            \"use_onnx\": False,\n",
    "            \"table_max_len\": 1024,\n",
    "            \"enable_mkldnn\": True,\n",
    "            \"table_algorithm\": \"SLANet\",\n",
    "            \"merge_no_span_structure\": True,\n",
    "            \"cpu_threads\": 16,\n",
    "        })()\n",
    "        tsr = TSR(args)\n",
    "        if os.environ.get('DATA_PATH_B'):  # 提交时会选择隐藏的测试数据集路径（A+B榜），数据集的格式与A榜数据相同，但数目不同（5360张）\n",
    "            base_dir = os.environ.get('DATA_PATH_B')\n",
    "        else:\n",
    "            base_dir = '/bohr/form-recognition-train-b6y2/v4'  # 示例，把A榜测试数据集路径作为测试集路径，仅开发时挂载A榜数据用于debug   # 示例，把A榜测试数据集路径作为测试集路径，仅开发时挂载A榜数据用于debug\n",
    "        with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for item in data:\n",
    "            path = os.path.join(base_dir, \"test_images\", item[\"image_path\"])\n",
    "            img = cv2.imread(path)\n",
    "            structure_res = tsr(img)\n",
    "            structure_str_list, bbox_list = structure_res\n",
    "            # boxes = np.array(bbox_list)\n",
    "            # for box in boxes.astype(int):\n",
    "            #     x1, y1, x2, y2 = box\n",
    "            #     cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            # output_path = os.path.join(img_output_dir, item[\"image_path\"])\n",
    "            # cv2.imwrite(output_path, img)\n",
    "            rows, cols = count_rows_and_columns(structure_str_list)\n",
    "            question = item[\"question\"]\n",
    "            question = question[0].lower() + question[1:]\n",
    "            q3 = f\"\"\"Based on the table, caption and html structure, {question}\n",
    "A) {item[\"options\"][0]}\n",
    "B) {item[\"options\"][1]}\n",
    "C) {item[\"options\"][2]}\n",
    "D) {item[\"options\"][3]}\n",
    "\"\"\"\n",
    "            self.ocr_data.put(((item[\"image_path\"], rows, cols), (path, item[\"caption\"], structure_str_list, q3)))\n",
    "            # print(f\"Put {item['image_path']} into queue\", flush=True)\n",
    "        self.ocr_data.put(None)\n",
    "\n",
    "    def process(self):\n",
    "        flag = True\n",
    "        while flag:\n",
    "            item = self.ocr_data.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            size = min(self.ocr_data.qsize(), self.batch_size)\n",
    "            batch_items = [item]\n",
    "            for _ in range(size):\n",
    "                item = self.ocr_data.get()\n",
    "                batch_items.append(item)\n",
    "            if batch_items[-1] is None:\n",
    "                batch_items.pop()\n",
    "                flag = False\n",
    "            batch_images = []\n",
    "            outputs = []\n",
    "            for output, input in batch_items:\n",
    "                outputs.append(output)\n",
    "                batch_images.append({\n",
    "                    \"img_path\": input[0],\n",
    "                    \"caption\": input[1],\n",
    "                    \"tsr\": input[2],\n",
    "                    \"q3\": input[3],\n",
    "                })\n",
    "            self.batch(outputs, batch_images)\n",
    "\n",
    "        with open('submission.json', 'w') as f:\n",
    "            json.dump(self.submission, f)\n",
    "\n",
    "    def batch(self, outputs, batch_images):\n",
    "        states = one_image.run_batch(batch_images)\n",
    "        for o, s in zip(outputs, states):\n",
    "            self.clean_out(o, s)\n",
    "\n",
    "    def clean_out(self, o, s):\n",
    "        # print(s, flush=True)\n",
    "        img_path, rows, cols = o\n",
    "        category = \"\"\n",
    "        answer = -1\n",
    "        try:\n",
    "            subject = s[\"subject\"]\n",
    "            match = re.search(r'[A-Za-z]', subject)\n",
    "            if match:\n",
    "                category = match.group(0).upper()\n",
    "                category = sub_list[l2i[category]]\n",
    "        except:\n",
    "            category = \"\"\n",
    "        try:\n",
    "            option = s[\"option\"]\n",
    "            match = re.search(r'[A-Za-z]', option)\n",
    "            if match:\n",
    "                answer = match.group(0).upper()\n",
    "                answer = l2i[answer]\n",
    "        except:\n",
    "            answer = -1\n",
    "        sub_item = {\n",
    "            \"image_path\": img_path,\n",
    "            \"category\": category,\n",
    "            \"cols\": cols,\n",
    "            \"rows\": rows,\n",
    "            \"answer\": answer,\n",
    "        }\n",
    "        # print(sub_item, flush=True)\n",
    "        self.submission.append(sub_item)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "id": "c1b896614c8ead1f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "worker = Worker()\n",
    "worker.run()"
   ],
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
