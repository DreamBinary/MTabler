{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def rewrite():\n",
    "    import os\n",
    "    import json\n",
    "    if os.environ.get('DATA_PATH_B'):\n",
    "        base_dir = os.environ.get('DATA_PATH_B')\n",
    "    else:\n",
    "        base_dir = '/bohr/form-recognition-train-b6y2/v4'\n",
    "    with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    with open(\"./data.json\", 'w') as f:\n",
    "        # write path to json\n",
    "        new_data = []\n",
    "        for d in data:\n",
    "            d[\"path\"] = os.path.join(base_dir, \"test_images\", d[\"image_path\"])\n",
    "            new_data.append(d)\n",
    "        json.dump(new_data, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6172a49844a268ac"
  },
  {
   "id": "9e4c9e8a2c56bb3f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import multiprocessing\n",
    "\n",
    "p = multiprocessing.Process(target=rewrite)\n",
    "p.start()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "id": "664dfe51317d5d0f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pkgs_path = \"/bohr/pkgs-7x29/v21/pkgs\"\n",
    "# llava_lib_path = \"/bohr/libb-bg5b/v3/llava\"\n",
    "# tsr_model_path = \"microsoft/table-structure-recognition-v1.1-all\"\n",
    "model_path = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "cache_path = \"/bohr/cach-rxl3/v11/cache\"\n",
    "table_model_dir = \"/bohr/ocrr-zlwd/v1/ch_ppstructure_openatom_SLANetv2_infer\"\n",
    "table_char_dict_path = \"/bohr/ocrr-zlwd/v1/table_structure_dict.txt\"\n",
    "\n",
    "new_json = \"./data.json\"\n",
    "# pkgs_path = \"/personal/pkgs\"\n",
    "# llava_lib_path = \"/personal/llava\"\n",
    "# model_path = \"lmms-lab/llava-onevision-qwen2-0.5b-ov\"\n",
    "# cache_path = \"/personal/cache\"\n",
    "# vllm_path = \"/personal/vllm\"\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.system(f\"pip3 install {pkgs_path}/* --ignore-installed\")\n",
    "# # 提交时可能不能联网，设置成离线模式防止联网失败报错\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_path\n",
    "os.environ[\"HF_HOME\"] = cache_path\n",
    "device = \"cuda\"\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ],
   "execution_count": " ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr.ppocr.data.imaug import transform\n",
    "from paddleocr.ppstructure.table.predict_structure import TableStructurer\n",
    "import warnings\n",
    "import re\n",
    "from swift.llm import (\n",
    "    get_model_tokenizer, get_template, inference, ModelType,\n",
    "    get_default_template_type\n",
    ")\n",
    "from swift.utils import seed_everything\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import logging\n",
    "#\n",
    "# multiprocessing.log_to_stderr(logging.INFO)\n",
    "# logger = multiprocessing.get_logger()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b41194affbee9a0"
  },
  {
   "id": "3b21a43f-6086-4da8-857c-5db5ce2ef37a",
   "cell_type": "code",
   "metadata": {},
   "source": [
    "l2i = defaultdict(lambda: -1)\n",
    "for i, letter in enumerate('ABCDEFGH'):\n",
    "    l2i[letter] = i\n",
    "sub_list = ('Physics', 'Mathematics', 'ComputerScience', 'QuantitativeBiology', 'QuantitativeFinance',\n",
    "            'Statistics', 'ElectricalEngineeringandSystemsScience', 'Economics', '')\n",
    "torch.cuda.empty_cache()"
   ],
   "execution_count": " ",
   "outputs": []
  },
  {
   "id": "926ffd3102503a4e",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class TSR(TableStructurer):\n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        data = {\"image\": img}\n",
    "        data = transform(data, self.preprocess_op)\n",
    "        img = data[0]\n",
    "        if img is None:\n",
    "            return None, 0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = img.copy()\n",
    "        if self.use_onnx:\n",
    "            input_dict = {}\n",
    "            input_dict[self.input_tensor.name] = img\n",
    "            outputs = self.predictor.run(self.output_tensors, input_dict)\n",
    "        else:\n",
    "            self.input_tensor.copy_from_cpu(img)\n",
    "            self.predictor.run()\n",
    "            outputs = []\n",
    "            for output_tensor in self.output_tensors:\n",
    "                output = output_tensor.copy_to_cpu()\n",
    "                outputs.append(output)\n",
    "\n",
    "        preds = {}\n",
    "        preds[\"structure_probs\"] = outputs[1]\n",
    "        preds[\"loc_preds\"] = outputs[0]\n",
    "\n",
    "        shape_list = np.expand_dims(data[-1], axis=0)\n",
    "        post_result = self.postprocess_op(preds, [shape_list])\n",
    "\n",
    "        structure_str_list = post_result[\"structure_batch_list\"][0]\n",
    "        bbox_list = post_result[\"bbox_batch_list\"][0]\n",
    "        structure_str_list = structure_str_list[0]\n",
    "        # structure_str_list = (\n",
    "        #         [\"<html>\", \"<body>\", \"<table>\"]\n",
    "        #         + structure_str_list\n",
    "        #         + [\"</table>\", \"</body>\", \"</html>\"]\n",
    "        # )\\\n",
    "        structure_str_list = [\"<table>\"] + structure_str_list + [\"</table>\"]\n",
    "        return structure_str_list, bbox_list"
   ],
   "execution_count": " ",
   "outputs": []
  },
  {
   "id": "490ec8f770a62d7e",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def count_rows_and_columns(html_tags):\n",
    "    rows = 0\n",
    "    max_columns = 0\n",
    "    current_columns = 0\n",
    "    rowspan_columns = {}\n",
    "    index = 0\n",
    "    columns_cnt = defaultdict(int)\n",
    "    while index < len(html_tags):\n",
    "        tag = html_tags[index]\n",
    "\n",
    "        if tag == '<tr>':\n",
    "            rows += 1\n",
    "            current_columns = 0\n",
    "\n",
    "            # Account for any ongoing rowspans from previous rows\n",
    "            for col, span in rowspan_columns.items():\n",
    "                if span > 1:\n",
    "                    current_columns += 1\n",
    "                    rowspan_columns[col] -= 1\n",
    "\n",
    "        elif tag.startswith('<td'):\n",
    "            colspan = 1\n",
    "            rowspan = 1\n",
    "\n",
    "            # Check if 'colspan' and 'rowspan' are in the subsequent strings\n",
    "            if index + 1 < len(html_tags) and 'colspan=\"' in html_tags[index + 1]:\n",
    "                colspan = int(html_tags[index + 1].strip().split('colspan=\"')[1].split('\"')[0])\n",
    "                index += 1  # Skip the colspan string\n",
    "            if index + 1 < len(html_tags) and 'rowspan=\"' in html_tags[index + 1]:\n",
    "                rowspan = int(html_tags[index + 1].strip().split('rowspan=\"')[1].split('\"')[0])\n",
    "                index += 1  # Skip the rowspan string\n",
    "\n",
    "            # Increment columns count\n",
    "            current_columns += colspan\n",
    "\n",
    "            # Track rowspans for subsequent rows\n",
    "            if rowspan > 1:\n",
    "                for _ in range(colspan):\n",
    "                    rowspan_columns[current_columns - _] = rowspan\n",
    "\n",
    "        elif tag == '</tr>':\n",
    "            # print(f\"Row {rows} has {current_columns} columns\")\n",
    "            columns_cnt[current_columns] += 1\n",
    "            max_columns = max(max_columns, current_columns)\n",
    "\n",
    "        index += 1\n",
    "    columns = max(columns_cnt, key=columns_cnt.get)\n",
    "    return rows, columns"
   ],
   "execution_count": " ",
   "outputs": []
  },
  {
   "id": "ce8b4d4174b19252",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class Worker:\n",
    "    def __init__(self):\n",
    "        self.llm = None\n",
    "        self.processor = None\n",
    "        self.batch_size = 8\n",
    "        self.submission = []\n",
    "        self.ocr_data = multiprocessing.Queue()\n",
    "\n",
    "    def run(self):\n",
    "        ocr_process = multiprocessing.Process(target=self.ocr)\n",
    "        ocr_process.start()\n",
    "        self.process()\n",
    "\n",
    "    def ocr(self):\n",
    "        args = type(\"Args\", (), {\n",
    "            \"table_model_dir\": table_model_dir,\n",
    "            \"table_char_dict_path\": table_char_dict_path,\n",
    "            \"use_gpu\": False,\n",
    "            # \"gpu_id\": 0,\n",
    "            # \"gpu_mem\": 500,\n",
    "            \"use_npu\": False,\n",
    "            \"use_mlu\": False,\n",
    "            \"use_xpu\": False,\n",
    "            \"precision\": \"fp32\",\n",
    "            \"benchmark\": False,\n",
    "            \"use_tensorrt\": False,\n",
    "            \"use_onnx\": False,\n",
    "            \"table_max_len\": 1024,\n",
    "            \"enable_mkldnn\": True,\n",
    "            \"table_algorithm\": \"SLANet\",\n",
    "            \"merge_no_span_structure\": True,\n",
    "            \"cpu_threads\": 16,\n",
    "        })()\n",
    "        tsr = TSR(args)\n",
    "        with open(new_json, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            # data = data[:10]\n",
    "        for item in data:\n",
    "            path = item[\"path\"]\n",
    "            img = cv2.imread(path)\n",
    "            structure_res = tsr(img)\n",
    "            structure_str_list, bbox_list = structure_res\n",
    "            # boxes = np.array(bbox_list)\n",
    "            # for box in boxes.astype(int):\n",
    "            #     x1, y1, x2, y2 = box\n",
    "            #     cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            # output_path = os.path.join(img_output_dir, item[\"image_path\"])\n",
    "            # cv2.imwrite(output_path, img)\n",
    "            rows, cols = count_rows_and_columns(structure_str_list)\n",
    "            question = item[\"question\"]\n",
    "            question = question[0].lower() + question[1:]\n",
    "            q1 = f'<image>This is a table image. The caption of the table is \"{item[\"caption\"]}\". The structure of the table in html format is as follows: {structure_str_list}.'\n",
    "            q3 = f\"\"\"Based on the table, caption and html structure, {question}\n",
    "A) {item[\"options\"][0]}\n",
    "B) {item[\"options\"][1]}\n",
    "C) {item[\"options\"][2]}\n",
    "D) {item[\"options\"][3]}\n",
    "\"\"\"\n",
    "            self.ocr_data.put(((item[\"image_path\"], rows, cols), (path, q1, q3)))\n",
    "            # print(f\"Put {item['image_path']} into queue\", flush=True)\n",
    "        self.ocr_data.put(None)\n",
    "\n",
    "    def process(self):\n",
    "        model_type = ModelType.qwen2_vl_7b_instruct\n",
    "        template_type = get_default_template_type(model_type)\n",
    "        model, tokenizer = get_model_tokenizer(\n",
    "            model_type, torch.bfloat16, model_id_or_path=model_path, model_kwargs={'device_map': 'auto'})\n",
    "        model.generation_config.max_new_tokens = 2\n",
    "        template = get_template(template_type, tokenizer)\n",
    "        seed_everything(42)\n",
    "        system = \"You are a helpful assistant. Provide only an label ([A-H] or [A-D]) of the correct answer for multiple-choice questions.\"\n",
    "\n",
    "        while True:\n",
    "            item = self.ocr_data.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            output, input = item\n",
    "            path, q1, q3 = input\n",
    "            history = [\n",
    "                ('user', q1),\n",
    "                ('assistant', f'I have a general understanding of the information in this table.')\n",
    "            ]\n",
    "            q2 = \"\"\"Based on the table, caption and html structure, which subject is most relevant to the table and caption?\n",
    "A) Physics\n",
    "B) Mathematics\n",
    "C) Computer Science\n",
    "D) Quantitative Biology\n",
    "E) Quantitative Finance\n",
    "F) Statistics\n",
    "G) Electrical Engineering and Systems Science\n",
    "H) Economics\n",
    "\"\"\"\n",
    "            question = item[\"question\"]\n",
    "            question = question[0].lower() + question[1:]\n",
    "            q3 = f\"\"\"Based on the table, caption and html structure, {question}\n",
    "A) {item[\"options\"][0]}\n",
    "B) {item[\"options\"][1]}\n",
    "C) {item[\"options\"][2]}\n",
    "D) {item[\"options\"][3]}\n",
    "\"\"\"\n",
    "            r2, history = inference(model, template, q2, history, system, [path])\n",
    "            r3, history = inference(model, template, q3, history, system, [path])\n",
    "            self.clean_out(output, r2, r3)\n",
    "\n",
    "        with open('submission.json', 'w') as f:\n",
    "            json.dump(self.submission, f)\n",
    "\n",
    "    def clean_out(self, o, r2, r3):\n",
    "        # print(s, flush=True)\n",
    "        img_path, rows, cols = o\n",
    "        category = \"\"\n",
    "        answer = -1\n",
    "        try:\n",
    "            match = re.search(r'[A-Za-z]', r2)\n",
    "            if match:\n",
    "                category = match.group(0).upper()\n",
    "                category = sub_list[l2i[category]]\n",
    "        except:\n",
    "            category = \"\"\n",
    "        try:\n",
    "            match = re.search(r'[A-Za-z]', r3)\n",
    "            if match:\n",
    "                answer = match.group(0).upper()\n",
    "                answer = l2i[answer]\n",
    "        except:\n",
    "            answer = -1\n",
    "        sub_item = {\n",
    "            \"image_path\": img_path,\n",
    "            \"category\": category,\n",
    "            \"cols\": cols,\n",
    "            \"rows\": rows,\n",
    "            \"answer\": answer,\n",
    "        }\n",
    "        # logger.info(sub_item)\n",
    "        # print(sub_item, flush=True)\n",
    "        self.submission.append(sub_item)"
   ],
   "execution_count": " ",
   "outputs": []
  },
  {
   "id": "c1b896614c8ead1f",
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "worker = Worker()\n",
    "p.join()\n",
    "worker.run()"
   ],
   "execution_count": " ",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
