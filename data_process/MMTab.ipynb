{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-16T13:04:03.556314Z",
     "start_time": "2024-08-16T13:04:02.780348Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/MMTab/MMTab-eval_test_data_49K.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "49726"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T13:04:05.181770Z",
     "start_time": "2024-08-16T13:04:05.173302Z"
    }
   },
   "id": "5fb6985dd89dd586",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "defaultdict(int,\n            {'table size detection': 1250,\n             'table cell locating': 1250,\n             'row and column extraction': 1250,\n             'merged cell detection': 1000,\n             'table cell extraction': 1250,\n             'table recognition with HTML': 780,\n             'table recognition with Latex': 106,\n             'table recognition with Markdown': 114,\n             'TABMWP_free_text': 5694,\n             'TABMWP_multi_choice': 1992,\n             'WTQ with the brief answer format': 4344,\n             'FeTaQA with the long answer format': 2003,\n             'HiTab with look-up': 1376,\n             'HiTab with numerical reasoning': 200,\n             'TAT-QA_span': 171,\n             'TAT-QA_arithmetic': 497,\n             'TAT-QA_multi-span': 92,\n             'TAT-QA_count': 12,\n             'TabFact simple statement': 2105,\n             'TabFact complex statement': 4740,\n             'InfoTabs_test_alpha1': 1800,\n             'InfoTabs_test_alpha2': 1800,\n             'InfoTabs_test_alpha3': 1800,\n             'table-to-text with highlighted cells': 7700,\n             'table-to-text with highlighted cells and operators': 1584,\n             'table-to-text for game summary': 334,\n             'table-to-text for biography': 1000,\n             'TabMCQ multi-choice question': 1029,\n             'AIT-QA_KPI-driven': 145,\n             'AIT-QA_Table-driven': 366,\n             'PubHealthTab': 1942})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "cnt = defaultdict(int)\n",
    "for item in data:\n",
    "    typ = item[\"original_query_type\"]\n",
    "    cnt[typ] += 1\n",
    "cnt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T13:05:52.713783Z",
     "start_time": "2024-08-16T13:05:52.695201Z"
    }
   },
   "id": "2b992fb0db748210",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "table size detection\n",
      "{'item_id': 'TSD_test_item_0', 'image_id': 'TABMWP_21652', 'input': 'I need to know the count of rows and columns in this specific table. Format your final answer as a JSON, using the structure {\"row_number\": \"m\", \"column_number\": \"n\"}.', 'output': 'This table has 3 rows and 3 columns. Thus, the final answer is {\"row_number\": \"3\", \"column_number\": \"3\"}.', 'task_type': 'TSD', 'dataset_name': 'TABMWP', 'original_query': 'None', 'answer_list': [[3, 3]], 'original_query_type': 'table size detection'}\n",
      "--------------------------------------------------\n",
      "table cell locating\n",
      "{'item_id': 'TCL_test_item_395', 'image_id': 'WTQ_204-csv_380', 'input': \"Analyze the provided table and identify the locations of these cells:\\n1. 'Raúl Hidalgo',\\n2. '4th Evicted',\\n3. 'Sonia Baby',\\n4. 'Year',\\n5. 'Bilbao',\\nProvide the cell locations using the JSON format {'value': '<cell value>', 'location': (row index, column index)}, where row and column indices start from 1. Some cell values may not be contained in this table. If so, represent their locations as 'DOES NOT EXIST'.\", 'output': \"The coordinates of target cells are listed below.\\n1. {'value': 'Raúl Hidalgo', 'location': (13, 1)}\\n2. {'value': '4th Evicted', 'location': (15, 5)}\\n3. {'value': 'Sonia Baby', 'location': (16, 1)}\\n4. {'value': 'Year', 'location': 'DOES NOT EXIST'}\\n5. {'value': 'Bilbao', 'location': (2, 2)}\", 'task_type': 'TCL', 'dataset_name': 'WTQ', 'original_query': 'None', 'answer_list': ['(13, 1)', '(15, 5)', '(16, 1)', 'DOES NOT EXIST', '(2, 2)'], 'original_query_type': 'table cell locating'}\n",
      "--------------------------------------------------\n",
      "row and column extraction\n",
      "{'item_id': 'RCE_test_item_486', 'image_id': 'HiTab_248_totto28105-2', 'input': 'Please provide the cell values contained in these columns of the table:\\ncolumn 13\\ncolumn 16\\n\\nRepresent the cells in a column with the JSON format {\"column_id\":\"<column index>\", \"cell_list\":\"<a list of cells in this column>\"}. For instance, {\"column_id\":\"5\", \"cell_list\": [\"152\", \"UN\", \"one last kiss\"]}.', 'output': 'The extracted column contents are listed below.\\nFor column 13: {\"column_id\": \"13\", \"cell_list\": [\\'\\', \\'lng\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\']}\\nFor column 16: {\"column_id\": \"16\", \"cell_list\": [\\'\\', \\'lost\\', \\'1\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'0\\', \\'1\\']}', 'task_type': 'RCE', 'dataset_name': 'HiTab', 'original_query': 'None', 'answer_list': [['', 'lng', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['', 'lost', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1']], 'original_query_type': 'row and column extraction'}\n",
      "--------------------------------------------------\n",
      "merged cell detection\n",
      "{'item_id': 'MCD_test_item_0', 'image_id': 'HiTab_2102', 'input': \"The picture contains a table. You task is to identify any merged cells in this table, and output the scope of each merged cell using the JSON format of {'top-left':(x, y), 'bottom-right':(z, w)}. The row id and column id should start from 1.\", 'output': \"The merged cell regions are as follows:\\n{'top-left':(1, 1), 'bottom-right':(2, 1)}\\n{'top-left':(2, 2), 'bottom-right':(2, 5)}\\n{'top-left':(3, 2), 'bottom-right':(3, 5)}\\n{'top-left':(8, 2), 'bottom-right':(8, 5)}\\n{'top-left':(11, 2), 'bottom-right':(11, 5)}\\n{'top-left':(14, 2), 'bottom-right':(14, 5)}\\n{'top-left':(17, 2), 'bottom-right':(17, 5)}\\n{'top-left':(22, 2), 'bottom-right':(22, 5)}\\n{'top-left':(25, 2), 'bottom-right':(25, 5)}.\", 'task_type': 'MCD', 'dataset_name': 'HiTab', 'original_query': 'None', 'answer_list': [\"{'top-left':(1, 1), 'bottom-right':(2, 1)}\", \"{'top-left':(2, 2), 'bottom-right':(2, 5)}\", \"{'top-left':(3, 2), 'bottom-right':(3, 5)}\", \"{'top-left':(8, 2), 'bottom-right':(8, 5)}\", \"{'top-left':(11, 2), 'bottom-right':(11, 5)}\", \"{'top-left':(14, 2), 'bottom-right':(14, 5)}\", \"{'top-left':(17, 2), 'bottom-right':(17, 5)}\", \"{'top-left':(22, 2), 'bottom-right':(22, 5)}\", \"{'top-left':(25, 2), 'bottom-right':(25, 5)}\"], 'original_query_type': 'merged cell detection'}\n",
      "--------------------------------------------------\n",
      "table cell extraction\n",
      "{'item_id': 'TCE_test_item_26', 'image_id': 'TABMWP_13894', 'input': 'Based on the table image, extract the value of the cell located in the subsequent postion:\\nthe 4th row and the 1st column\\n\\nShow the cell value in the JSON format {\"row_id\":\"m\", \"column_id\":\"n\", \"cell_value\":\"<Corresponding Cell Value>\"}.', 'output': 'The target cell value in the 4th row and the 1st column is {\"row_id\":\"4\", \"column_id\":\"1\", \"cell_value\":\"7\"}.', 'task_type': 'TCE', 'dataset_name': 'TABMWP', 'original_query': 'None', 'answer_list': ['7'], 'original_query_type': 'table cell extraction'}\n",
      "--------------------------------------------------\n",
      "table recognition with HTML\n",
      "{'item_id': 'table_recognition_test_item_0', 'image_id': 'HiTab_178_totto21176-4', 'input': 'Given a table image, can you convert the table into an HTML table in the text form?', 'output': '<table border=\"1\" cellspacing=\"0\">\\n<tr> <td rowspan=\"2\"> year </td> <td rowspan=\"2\"> team </td> <td colspan=\"2\"> games </td> <td colspan=\"5\"> receiving </td> <td colspan=\"5\"> rushing </td> <td colspan=\"5\"> returning </td> <td colspan=\"2\"> fumbles </td> </tr>\\n<tr> <td> gp </td> <td> gs </td> <td> rec </td> <td> yds </td> <td> avg </td> <td> lng </td> <td> td </td> <td> att </td> <td> yds </td> <td> avg </td> <td> lng </td> <td> td </td> <td> ret </td> <td> yds </td> <td> avg </td> <td> lng </td> <td> td </td> <td> fum </td> <td> lost </td> </tr>\\n<tr> <td> 2012 </td> <td> dal </td> <td> 10 </td> <td> 0 </td> <td> 15 </td> <td> 128 </td> <td> 8.5 </td> <td> 20 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td> 2013 </td> <td> dal </td> <td> 14 </td> <td> 3 </td> <td> 39 </td> <td> 368 </td> <td> 9.4 </td> <td> 23 </td> <td> 2 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 11 </td> <td> 79 </td> <td> 7.2 </td> <td> 14 </td> <td> 0 </td> <td> 1 </td> <td> 0 </td> </tr>\\n<tr> <td> 2014 </td> <td> dal </td> <td> 16 </td> <td> 2 </td> <td> 37 </td> <td> 420 </td> <td> 11.4 </td> <td> 45 </td> <td> 4 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 2 </td> <td> 2 </td> </tr>\\n<tr> <td> 2015 </td> <td> dal </td> <td> 16 </td> <td> 3 </td> <td> 52 </td> <td> 536 </td> <td> 10.3 </td> <td> 30 </td> <td> 5 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 12 </td> <td> 69 </td> <td> 5.8 </td> <td> 22 </td> <td> 0 </td> <td> 2 </td> <td> 2 </td> </tr>\\n<tr> <td> 2016 </td> <td> dal </td> <td> 16 </td> <td> 6 </td> <td> 75 </td> <td> 833 </td> <td> 11.1 </td> <td> 47 </td> <td> 5 </td> <td> 1 </td> <td> 7 </td> <td> 7.0 </td> <td> 7 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td> 2017 </td> <td> dal </td> <td> 15 </td> <td> 4 </td> <td> 36 </td> <td> 314 </td> <td> 8.7 </td> <td> 54 </td> <td> 4 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 2 </td> <td> 19 </td> <td> 9.5 </td> <td> 15 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td> 2018 </td> <td> dal </td> <td> 16 </td> <td> 4 </td> <td> 65 </td> <td> 672 </td> <td> 10.3 </td> <td> 32 </td> <td> 3 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 12 </td> <td> 69 </td> <td> 5.8 </td> <td> 14 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td colspan=\"2\"> career </td> <td> 103 </td> <td> 22 </td> <td> 319 </td> <td> 3,271 </td> <td> 54 </td> <td> 10.3 </td> <td> 23 </td> <td> 1 </td> <td> 7 </td> <td> 7.0 </td> <td> 7 </td> <td> 0 </td> <td> 40 </td> <td> 239 </td> <td> 6.0 </td> <td> 22 </td> <td> 0 </td> <td> 5 </td> <td> 4 </td> </tr>\\n</table>', 'task_type': 'TR', 'dataset_name': 'HiTab', 'original_query': '', 'answer_list': ['<table border=\"1\" cellspacing=\"0\">\\n<tr> <td rowspan=\"2\"> year </td> <td rowspan=\"2\"> team </td> <td colspan=\"2\"> games </td> <td colspan=\"5\"> receiving </td> <td colspan=\"5\"> rushing </td> <td colspan=\"5\"> returning </td> <td colspan=\"2\"> fumbles </td> </tr>\\n<tr> <td> gp </td> <td> gs </td> <td> rec </td> <td> yds </td> <td> avg </td> <td> lng </td> <td> td </td> <td> att </td> <td> yds </td> <td> avg </td> <td> lng </td> <td> td </td> <td> ret </td> <td> yds </td> <td> avg </td> <td> lng </td> <td> td </td> <td> fum </td> <td> lost </td> </tr>\\n<tr> <td> 2012 </td> <td> dal </td> <td> 10 </td> <td> 0 </td> <td> 15 </td> <td> 128 </td> <td> 8.5 </td> <td> 20 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td> 2013 </td> <td> dal </td> <td> 14 </td> <td> 3 </td> <td> 39 </td> <td> 368 </td> <td> 9.4 </td> <td> 23 </td> <td> 2 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 11 </td> <td> 79 </td> <td> 7.2 </td> <td> 14 </td> <td> 0 </td> <td> 1 </td> <td> 0 </td> </tr>\\n<tr> <td> 2014 </td> <td> dal </td> <td> 16 </td> <td> 2 </td> <td> 37 </td> <td> 420 </td> <td> 11.4 </td> <td> 45 </td> <td> 4 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 2 </td> <td> 2 </td> </tr>\\n<tr> <td> 2015 </td> <td> dal </td> <td> 16 </td> <td> 3 </td> <td> 52 </td> <td> 536 </td> <td> 10.3 </td> <td> 30 </td> <td> 5 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 12 </td> <td> 69 </td> <td> 5.8 </td> <td> 22 </td> <td> 0 </td> <td> 2 </td> <td> 2 </td> </tr>\\n<tr> <td> 2016 </td> <td> dal </td> <td> 16 </td> <td> 6 </td> <td> 75 </td> <td> 833 </td> <td> 11.1 </td> <td> 47 </td> <td> 5 </td> <td> 1 </td> <td> 7 </td> <td> 7.0 </td> <td> 7 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td> 2017 </td> <td> dal </td> <td> 15 </td> <td> 4 </td> <td> 36 </td> <td> 314 </td> <td> 8.7 </td> <td> 54 </td> <td> 4 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 2 </td> <td> 19 </td> <td> 9.5 </td> <td> 15 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td> 2018 </td> <td> dal </td> <td> 16 </td> <td> 4 </td> <td> 65 </td> <td> 672 </td> <td> 10.3 </td> <td> 32 </td> <td> 3 </td> <td> 0 </td> <td> 0 </td> <td> 0.0 </td> <td> 0 </td> <td> 0 </td> <td> 12 </td> <td> 69 </td> <td> 5.8 </td> <td> 14 </td> <td> 0 </td> <td> 0 </td> <td> 0 </td> </tr>\\n<tr> <td colspan=\"2\"> career </td> <td> 103 </td> <td> 22 </td> <td> 319 </td> <td> 3,271 </td> <td> 54 </td> <td> 10.3 </td> <td> 23 </td> <td> 1 </td> <td> 7 </td> <td> 7.0 </td> <td> 7 </td> <td> 0 </td> <td> 40 </td> <td> 239 </td> <td> 6.0 </td> <td> 22 </td> <td> 0 </td> <td> 5 </td> <td> 4 </td> </tr>\\n</table>'], 'original_query_type': 'table recognition with HTML'}\n",
      "--------------------------------------------------\n",
      "table recognition with Latex\n",
      "{'item_id': 'table_recognition_test_item_15', 'image_id': 'TabFact_2-12475284-5.html.csv', 'input': 'Please review this table image and return a text representation of the table in the latex format.', 'output': '\\\\begin{tabular}{|c|c|c|c|c|}\\n\\\\hline\\n place & player & country & score & to par   \\\\\\\\\\n\\\\hline\\n t1 & billy andrade & united states & 67 + 69 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t1 & luke donald & england & 68 + 68 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t1 & henrik stenson & sweden & 68 + 68 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t1 & tim herron & united states & 69 + 67 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t5 & davis love iii & united states & 68 + 69 = 137 & - 7   \\\\\\\\\\n\\\\hline\\n t5 & geoff ogilvy & australia & 69 + 68 = 137 & - 7   \\\\\\\\\\n\\\\hline\\n t5 & tiger woods & united states & 69 + 68 = 137 & - 7   \\\\\\\\\\n\\\\hline\\n t8 & fred funk & united states & 69 + 69 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n t8 & billy mayfair & united states & 69 + 69 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n t8 & chris riley & united states & 66 + 72 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n t8 & david toms & united states & 71 + 67 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n\\\\end{tabular}', 'task_type': 'TR', 'dataset_name': 'TabFact', 'original_query': '', 'answer_list': ['\\\\begin{tabular}{|c|c|c|c|c|}\\n\\\\hline\\n place & player & country & score & to par   \\\\\\\\\\n\\\\hline\\n t1 & billy andrade & united states & 67 + 69 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t1 & luke donald & england & 68 + 68 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t1 & henrik stenson & sweden & 68 + 68 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t1 & tim herron & united states & 69 + 67 = 136 & - 8   \\\\\\\\\\n\\\\hline\\n t5 & davis love iii & united states & 68 + 69 = 137 & - 7   \\\\\\\\\\n\\\\hline\\n t5 & geoff ogilvy & australia & 69 + 68 = 137 & - 7   \\\\\\\\\\n\\\\hline\\n t5 & tiger woods & united states & 69 + 68 = 137 & - 7   \\\\\\\\\\n\\\\hline\\n t8 & fred funk & united states & 69 + 69 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n t8 & billy mayfair & united states & 69 + 69 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n t8 & chris riley & united states & 66 + 72 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n t8 & david toms & united states & 71 + 67 = 138 & - 6   \\\\\\\\\\n\\\\hline\\n\\\\end{tabular}'], 'original_query_type': 'table recognition with Latex'}\n",
      "--------------------------------------------------\n",
      "table recognition with Markdown\n",
      "{'item_id': 'table_recognition_test_item_35', 'image_id': 'TabFact_1-27225944-3.html.csv', 'input': 'Read the shown table in this image and give me the reconstructed table in the markdown text format.', 'output': '| team | outgoing manager | manner of departure | date of vacancy | replaced by | date of appointment | position in table |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| rnk split | tonći bašić | removed from position | 2 2010 | ivan katalinić | 2 2010 | pre - season |\\n| slaven belupo | zlatko dalić | mutual consent | 2 2010 | mile petković | 7 2010 | pre - season |\\n| istra 1961 | ante miše | sacked | 3 2010 | robert jarni | 4 2010 | 16th |\\n| lokomotiva | roy ferenčina | mutual consent | 2 2010 | ljupko petrović | 2 2010 | 12th |\\n| hrvatski dragovoljac | damir biškup | removed from position | 3 2010 | ivan pudar | 3 2010 | 15th |\\n| rijeka | nenad gračan | mutual consent | 6 2010 | elvis scoria | 8 2010 | 6th |\\n| hrvatski dragovoljac | ivan pudar | mutual consent | 7 2010 | davor mladina | 7 2010 | 16th |', 'task_type': 'TR', 'dataset_name': 'TabFact', 'original_query': '', 'answer_list': ['| team | outgoing manager | manner of departure | date of vacancy | replaced by | date of appointment | position in table |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| rnk split | tonći bašić | removed from position | 2 2010 | ivan katalinić | 2 2010 | pre - season |\\n| slaven belupo | zlatko dalić | mutual consent | 2 2010 | mile petković | 7 2010 | pre - season |\\n| istra 1961 | ante miše | sacked | 3 2010 | robert jarni | 4 2010 | 16th |\\n| lokomotiva | roy ferenčina | mutual consent | 2 2010 | ljupko petrović | 2 2010 | 12th |\\n| hrvatski dragovoljac | damir biškup | removed from position | 3 2010 | ivan pudar | 3 2010 | 15th |\\n| rijeka | nenad gračan | mutual consent | 6 2010 | elvis scoria | 8 2010 | 6th |\\n| hrvatski dragovoljac | ivan pudar | mutual consent | 7 2010 | davor mladina | 7 2010 | 16th |'], 'original_query_type': 'table recognition with Markdown'}\n",
      "--------------------------------------------------\n",
      "TABMWP_free_text\n",
      "{'item_id': 'TABMWP_8', 'image_id': 'TABMWP_8', 'input': 'Problem: \\nHannah baked cookies each day for a bake sale. How many more cookies did Hannah bake on Saturday than on Sunday? (Unit: cookies)\\nSolve the above problem based on the table titled \\'Cookies baked\\'. Provide a concluding answer in a JSON structure, using the format {\"answer\": \"<YOUR ANSWER>\"}.', 'output': 'Find the numbers in the table.\\n\\nSaturday: 281\\nSunday: 263\\n\\nNow subtract: 281 - 263 = 18.\\n\\nHannah baked 18 more cookies on Saturday.\\n\\nTherefore, the final answer is {\"answer\": \"18\"}.', 'task_type': 'TQA', 'dataset_name': 'TABMWP', 'original_query': 'Hannah baked cookies each day for a bake sale. How many more cookies did Hannah bake on Saturday than on Sunday?', 'answer_list': ['18'], 'original_query_type': 'TABMWP_free_text'}\n",
      "--------------------------------------------------\n",
      "TABMWP_multi_choice\n",
      "{'item_id': 'TABMWP_25', 'image_id': 'TABMWP_25', 'input': 'Given the table about \\'Coin collections\\', solve the following math problem step by step. Conclude your response with a final answer in the JSON format {\"answer\": \"<YOUR ANSWER>\"}.\\nSome friends discussed the sizes of their coin collections. Who has the most coins? (A) Erica (B) Hunter (C) Damon (D) Larry', 'output': 'Find the greatest number in the table. Remember to compare the numbers starting with the highest place value. The greatest number is 663.\\n\\nNow find the corresponding name. Hunter corresponds to 663.\\n\\nSo, the answer is {\"answer\": \"Hunter\"}.', 'task_type': 'TQA', 'dataset_name': 'TABMWP', 'original_query': 'Some friends discussed the sizes of their coin collections. Who has the most coins?', 'answer_list': ['Hunter'], 'original_query_type': 'TABMWP_multi_choice'}\n",
      "--------------------------------------------------\n",
      "WTQ with the brief answer format\n",
      "{'item_id': 'WTQ_nu-0', 'image_id': 'WTQ_203-csv_733', 'input': 'Analyze the table image which is related to \\'2008 Clásica de San Sebastián\\' and write a brief answer to the question that follows. Show your answer in the JSON format {\"answer\": [<a list of answer strings>]}.\\nwhich country had the most cyclists finish within the top 10?', 'output': 'Based on the table, the final answer is {\"answer\": [\\'Italy\\']}.', 'task_type': 'TQA', 'dataset_name': 'WTQ', 'original_query': 'which country had the most cyclists finish within the top 10?', 'answer_list': ['Italy'], 'original_query_type': 'WTQ with the brief answer format'}\n",
      "--------------------------------------------------\n",
      "FeTaQA with the long answer format\n",
      "{'item_id': 'FeTaQA_2206', 'image_id': 'FeTaQA_dev_example-2205', 'input': \"Conduct table question answering task based on the given table about 'Shagun Sharma' with the table title 'Television'.\\nWhat TV shows was Shagun Sharma seen in 2019?\", 'output': 'In 2019, Shagun Sharma played in the roles as Pernia in Laal Ishq, Vikram Betaal Ki Rahasya Gatha as Rukmani/Kashi and Shaadi Ke Siyape as Dua.', 'task_type': 'TQA', 'dataset_name': 'FeTaQA', 'original_query': 'What TV shows was Shagun Sharma seen in 2019?', 'answer_list': ['In 2019, Shagun Sharma played in the roles as Pernia in Laal Ishq, Vikram Betaal Ki Rahasya Gatha as Rukmani/Kashi and Shaadi Ke Siyape as Dua.'], 'original_query_type': 'FeTaQA with the long answer format'}\n",
      "--------------------------------------------------\n",
      "HiTab with look-up\n",
      "{'item_id': 'HiTab_c26dd7d31e73948ab9deb29ca1fc89ef', 'image_id': 'HiTab_100', 'input': 'Observe the excel table screenshot named \\'agri-food industry sub-groups for workers aged 15 years and over, two agricultural regions of ontario, 2011\\' and succinctly answer the question that follows. Present the final answer in a JSON format {\"answer\": [<a list of answer strings>]} like {\"answer\": [\"2.27\", \"41.4\"]}.\\nin eastern ontario, what percent of french-language workers have worked in the restaurant and food services sector?', 'output': 'Based on the table information, the final answer is {\"answer\": [\"52.1\"]}.', 'task_type': 'TQA', 'dataset_name': 'HiTab', 'original_query': 'in eastern ontario, what percent of french-language workers have worked in the restaurant and food services sector?', 'answer_list': ['52.1'], 'original_query_type': 'HiTab with look-up'}\n",
      "--------------------------------------------------\n",
      "HiTab with numerical reasoning\n",
      "{'item_id': 'HiTab_510476dd6fe55a9c97d995c55e2b401e', 'image_id': 'HiTab_1004', 'input': 'how many percent of university graduates among second-generation black women who originated from jamaica was higher than that of men in 2016?\\nAddress this question in detail according to the provided excel table whose title is \\'percentage of canadian-born black immigrants aged 25 to 59 with a postsecondary diploma, by sex and region or country of ancestry, 2016\\'. In addition, output the final answer as JSON in the format {\"answer\": [<a list of answer strings>]}.', 'output': 'According to this excel table, we have the following calculations: 31.3-15.8 = 15.5.\\nThus, the final answer is {\"answer\": [\"15.5\"]}.', 'task_type': 'TQA', 'dataset_name': 'HiTab', 'original_query': 'how many percent of university graduates among second-generation black women who originated from jamaica was higher than that of men in 2016?', 'answer_list': ['15.5'], 'original_query_type': 'HiTab with numerical reasoning'}\n",
      "--------------------------------------------------\n",
      "TAT-QA_span\n",
      "{'item_id': 'TAT-QA_870c1bda-0cd7-4bd0-bba6-8deb178e24ce', 'image_id': 'TAT-QA_53474060-2736-46cb-bd97-1eb42f0ff3c1', 'input': 'Analyze the table and respond to the question that follows. Return the final result as JSON in the format {\"answer\": [<a list of answer strings>]}.\\nIn which year was the amount for Sensors the largest?', 'output': 'Because 918>914>814, the answer is {\"answer\": [\"2018\"]}.', 'task_type': 'TQA', 'dataset_name': 'TAT-QA', 'original_query': 'In which year was the amount for Sensors the largest?', 'answer_list': ['2018'], 'original_query_type': 'TAT-QA_span'}\n",
      "--------------------------------------------------\n",
      "TAT-QA_arithmetic\n",
      "{'item_id': 'TAT-QA_b2786c1a-37de-4120-b03c-32bf5c81f157', 'image_id': 'TAT-QA_53474060-2736-46cb-bd97-1eb42f0ff3c1', 'input': 'Consult the table picture and reply to the ensuing question. Output the final answer as JSON in the format {\"answer\": [<a list of answer strings>]}.\\nWhat was the change in the amount for Appliances in 2019 from 2018?', 'output': 'According to this table, we have the following calculations: 680-774 = -94.\\nThus, the answer is {\"answer\": [\"-94\"]}.', 'task_type': 'TQA', 'dataset_name': 'TAT-QA', 'original_query': 'What was the change in the amount for Appliances in 2019 from 2018?', 'answer_list': ['-94'], 'original_query_type': 'TAT-QA_arithmetic'}\n",
      "--------------------------------------------------\n",
      "TAT-QA_multi-span\n",
      "{'item_id': 'TAT-QA_d47306cf-e276-4836-a827-ebebdc47e078', 'image_id': 'TAT-QA_6bf238a5-0a3e-492d-91f8-7f62d3b37fba', 'input': 'Read the table to answer the following questions in brief. Format the ultimate answer as a JSON, using the structure {\"answer\": [<a list of answer strings>]}.\\nWhat financial items are listed in the table?', 'output': 'Based on the table information, the answer is {\"answer\": [\"Defined contribution schemes\", \"Defined benefit schemes\", \"\"]}.', 'task_type': 'TQA', 'dataset_name': 'TAT-QA', 'original_query': 'What financial items are listed in the table?', 'answer_list': ['Defined contribution schemes', 'Defined benefit schemes', ''], 'original_query_type': 'TAT-QA_multi-span'}\n",
      "--------------------------------------------------\n",
      "TAT-QA_count\n",
      "{'item_id': 'TAT-QA_8f61e8be-18ee-4226-bb65-e1d1b4dfa8ec', 'image_id': 'TAT-QA_cc4f089d-e7bf-4b00-a096-48a3eed39f86', 'input': 'Examine the table image and answer the ensuing question in detail. Present the final answer in a JSON format {\"answer\": [<a list of answer strings>]}.\\nHow many assumptions are used by the company when using the Black-Scholes-Merton option pricing model?', 'output': 'By referring to the table, we are required to enumerate the following:\\nThe expected life input is based on historical exercise patterns and post-vesting termination behavior##the risk-free interest rate input is based on U.S. Treasury instruments##the annualized dividend yield input is based on the per share dividend declared by the Board##the volatility input is calculated based on the implied volatility of our publicly traded options.\\nConsequently, the answer is {\"answer\": [\"4\"]}.', 'task_type': 'TQA', 'dataset_name': 'TAT-QA', 'original_query': 'How many assumptions are used by the company when using the Black-Scholes-Merton option pricing model?', 'answer_list': ['4'], 'original_query_type': 'TAT-QA_count'}\n",
      "--------------------------------------------------\n",
      "TabFact simple statement\n",
      "{'item_id': 'TabFact_test_0', 'image_id': 'TabFact_1-2509350-3.html.csv', 'input': 'Based on the table image about \\'tomina province\\' and the subsequent sentence, determine if the table entails or disputes the subsequent sentence. Show your final answer in the JSON format {\"answer\": \"<YOUR ANSWER>\"}.\\nsentence: the padilla municipality language for quechua is 2181', 'output': 'Considering the information from the table, it entails the sentence. So, the answer is {\"answer\": \"entails\"}.', 'task_type': 'TFV', 'dataset_name': 'TabFact', 'original_query': 'the padilla municipality language for quechua is 2181', 'answer_list': ['entails'], 'original_query_type': 'TabFact simple statement'}\n",
      "--------------------------------------------------\n",
      "TabFact complex statement\n",
      "{'item_id': 'TabFact_test_2105', 'image_id': 'TabFact_2-1570274-4.html.csv', 'input': 'Examine whether the table substantiates or contradicts the subsequent hypothesis. Output the final answer as JSON in the format {\"answer\": \"<YOUR ANSWER>\"}.\\ntable title: \\'tony lema\\'\\nhypothesis: the only tournament that tony lema won in was the open championship', 'output': 'Based on the table data, we can affirm the truth of the hypothesis. Consequently, the answer is {\"answer\": \"substantiates\"}.', 'task_type': 'TFV', 'dataset_name': 'TabFact', 'original_query': 'the only tournament that tony lema won in was the open championship', 'answer_list': ['substantiates'], 'original_query_type': 'TabFact complex statement'}\n",
      "--------------------------------------------------\n",
      "InfoTabs_test_alpha1\n",
      "{'item_id': 'InfoTabs_test_alpha1_0', 'image_id': 'InfoTabs_T12', 'input': 'Give you a table extracted from wikipedia infobox, determine whether the following sentence is \\'confirmed\\' or \\'disproved\\' by the table. If the table does not provide enough evidence for the sentence, then output \\'neutral\\' as the answer. The final result should be presented in the JSON format of {\"answer\": \"<YOUR ANSWER>\"}.\\nAksel V. Johannesen serves in the Faroe Islands government. ', 'output': 'Based on the table information, the given sentence is confirmed by the table. Thus, the answer is {\"answer\": \"confirmed\"}.', 'task_type': 'TFV', 'dataset_name': 'InfoTabs', 'original_query': 'Aksel V. Johannesen serves in the Faroe Islands government.', 'answer_list': ['confirmed'], 'original_query_type': 'InfoTabs_test_alpha1'}\n",
      "--------------------------------------------------\n",
      "InfoTabs_test_alpha2\n",
      "{'item_id': 'InfoTabs_test_alpha2_1800', 'image_id': 'InfoTabs_T31', 'input': 'Using the given table, determine if the sentence is entailed or \\'disputed\\'. If the table does not provide sufficient information, the answer should be \\'not enough information\\'. Present the final answer in a JSON format {\"answer\": \"<YOUR ANSWER>\"} like {\"answer\": \"entailed\"}.\\nEva Mendes was born in the Fall of 1974.', 'output': 'Using the table as reference, the sentence is false. Thus, the final answer is {\"answer\": \"disputed\"}.', 'task_type': 'TFV', 'dataset_name': 'InfoTabs', 'original_query': 'Eva Mendes was born in the Fall of 1974.', 'answer_list': ['disputed'], 'original_query_type': 'InfoTabs_test_alpha2'}\n",
      "--------------------------------------------------\n",
      "InfoTabs_test_alpha3\n",
      "{'item_id': 'InfoTabs_test_alpha3_3600', 'image_id': 'InfoTabs_T2045', 'input': 'Most of the survivors were crew.\\n Does the provided table \\'supports\\' or \\'disproves\\' the above statement? Should we classify it as \\'neutral\\' if there is no enough information? Provide the final answer in the JSON structure, using the format {\"answer\": \"<YOUR ANSWER>\"}.', 'output': 'Based on the table information, the given statement is true. Thus, the answer is {\"answer\": \"supports\"}.', 'task_type': 'TFV', 'dataset_name': 'InfoTabs', 'original_query': 'Most of the survivors were crew.', 'answer_list': ['supports'], 'original_query_type': 'InfoTabs_test_alpha3'}\n",
      "--------------------------------------------------\n",
      "table-to-text with highlighted cells\n",
      "{'item_id': 'ToTTo_test_item_0', 'image_id': 'ToTTo_test_table_0', 'input': \"Using the table regarding 'Isotopes of fluorine' and its associated metadata, compose a one-sentence description of the data emphasized in the highlighted table cells.\", 'output': 'None', 'task_type': 'T2T', 'dataset_name': 'ToTTo', 'original_query': 'None', 'answer_list': ['None'], 'original_query_type': 'table-to-text with highlighted cells'}\n",
      "--------------------------------------------------\n",
      "table-to-text with highlighted cells and operators\n",
      "{'item_id': 'HiTab_t2t_test_0', 'image_id': 'HiTab_100_t2t_test_0', 'input': \"I'd like you to generate a descriptive sentence about the highlighted cells in the provided table, and this table is titled 'agri-food industry sub-groups for workers aged 15 years and over, two agricultural regions of ontario, 2011'.\", 'output': 'in eastern ontario, 52.1% of french-language workers worked in the restaurant and food services sector.', 'task_type': 'T2T', 'dataset_name': 'HiTab_t2t', 'original_query': 'None', 'answer_list': ['in eastern ontario, 52.1% of french-language workers worked in the restaurant and food services sector.'], 'original_query_type': 'table-to-text with highlighted cells and operators'}\n",
      "--------------------------------------------------\n",
      "table-to-text for game summary\n",
      "{'item_id': 'Rotowire_test_item_0', 'image_id': 'Rotowire_test_table_0', 'input': 'Based on the shown data statistics of an NBA game on 28/03/2017, give me a detailed summary for this game.', 'output': \"It was a huge night for Portland 's young stars, and in particular, recently acquired big man Jusuf Nurkic. Nurkic had a career-high 33 points on 12-of-15 shooting and 9-of-11 at the free-throw line against his former team. Offense was n't the only thing Nurkic provided, though, as he pulled down a whopping 16 rebounds to go along with two steals and three blocks. The young center continues to grow in his new starting role with Portland. Nurkic was not even his team 's high scorer, however, as shooting guard C.J. McCollum exploded for 39 points. McCollum shot 15-of-24 from the field and splashed home three three-pointers on the night. In addition, McCollum had five rebounds, three assists, and went 6-of-6 at the free-throw line. For Denver, young big man Nikola Jokic made an impact with 17 points, eight rebounds, and eight assists. Veteran starter Jameer Nelson also contributed somewhat surprisingly with a team-high 23 points on the night.\", 'task_type': 'T2T', 'dataset_name': 'Rotowire', 'original_query': 'None', 'answer_list': [\"It was a huge night for Portland 's young stars, and in particular, recently acquired big man Jusuf Nurkic. Nurkic had a career-high 33 points on 12-of-15 shooting and 9-of-11 at the free-throw line against his former team. Offense was n't the only thing Nurkic provided, though, as he pulled down a whopping 16 rebounds to go along with two steals and three blocks. The young center continues to grow in his new starting role with Portland. Nurkic was not even his team 's high scorer, however, as shooting guard C.J. McCollum exploded for 39 points. McCollum shot 15-of-24 from the field and splashed home three three-pointers on the night. In addition, McCollum had five rebounds, three assists, and went 6-of-6 at the free-throw line. For Denver, young big man Nikola Jokic made an impact with 17 points, eight rebounds, and eight assists. Veteran starter Jameer Nelson also contributed somewhat surprisingly with a team-high 23 points on the night.\"], 'original_query_type': 'table-to-text for game summary'}\n",
      "--------------------------------------------------\n",
      "table-to-text for biography\n",
      "{'item_id': 'WikiBIO_test_item_0', 'image_id': 'WikiBIO_test_12333307', 'input': \"This picture contains basic information of 'Zach crouch'. Utilize this information to write a introduction for this person.\", 'output': \"Zachary quinn crouch (born october 26, 1965 in folsom, california) is a former relief pitcher in major league baseball who played briefly for the boston red sox during the 1988 season. Crouch, a 6' 3 '', 180 lb. Left-handed specialist, was selected by the boston red sox in third round of the 1984 amateur draft. He pitched at five different minor league levels from 1985-1988 before joining the big team. In 102 minor league games, crouch posted a 27-31 record with a 3.63 era in 533.2 innings pitched. In three major league appearances, he recorded a 6.75 era without a decision in 1 1/3 innings.\", 'task_type': 'T2T', 'dataset_name': 'WikiBIO', 'original_query': 'None', 'answer_list': [\"Zachary quinn crouch (born october 26, 1965 in folsom, california) is a former relief pitcher in major league baseball who played briefly for the boston red sox during the 1988 season. Crouch, a 6' 3 '', 180 lb. Left-handed specialist, was selected by the boston red sox in third round of the 1984 amateur draft. He pitched at five different minor league levels from 1985-1988 before joining the big team. In 102 minor league games, crouch posted a 27-31 record with a 3.63 era in 533.2 innings pitched. In three major league appearances, he recorded a 6.75 era without a decision in 1 1/3 innings.\"], 'original_query_type': 'table-to-text for biography'}\n",
      "--------------------------------------------------\n",
      "TabMCQ multi-choice question\n",
      "{'item_id': 'TabMCQ_test_22', 'image_id': 'TabMCQ_regents-01', 'input': 'Choose the correct answer option based on the table and the question. Return the result as JSON in the format {\"answer\": \"<YOUR ANSWER>\"}, e.g., {\"answer\": \"A. England\"}.\\nThe spring equinox is the day with the _______ period of daylight?\\n1. midrange\\n2. shortest\\n3. longest\\n4. None of the above', 'output': 'Based on the provided table, the correct answer option: {\"answer\": \"1. midrange\"}.', 'task_type': 'TQA', 'dataset_name': 'TabMCQ', 'original_query': 'The spring equinox is the day with the _______ period of daylight?', 'answer_list': ['1. midrange'], 'original_query_type': 'TabMCQ multi-choice question'}\n",
      "--------------------------------------------------\n",
      "AIT-QA_KPI-driven\n",
      "{'item_id': 'AIT-QA_q-0', 'image_id': 'AIT-QA_tab-0', 'input': 'After examining the table concerning the airline industry, answer the question that follows. Your final answer should be in the JSON structure, formatted as {\"answer\": \"<YOUR ANSWER>\"}. For instance, {\"answer\": \"1936\"}.\\nHow much money did United spend for aircraft fuel in 2016?', 'output': 'Using the table as reference, the answer is {\"answer\": \"$5,813\"}.', 'task_type': 'TQA', 'dataset_name': 'AIT-QA', 'original_query': 'How much money did United spend for aircraft fuel in 2016?', 'answer_list': ['$5,813'], 'original_query_type': 'AIT-QA_KPI-driven'}\n",
      "--------------------------------------------------\n",
      "AIT-QA_Table-driven\n",
      "{'item_id': 'AIT-QA_q-1', 'image_id': 'AIT-QA_tab-0', 'input': 'According to the given table about an airline company, show the answer to the following question. Your final answer should be in the JSON structure, formatted as {\"answer\": \"<YOUR ANSWER>\"}. For instance, {\"answer\": \"1936\"}.\\nHow many gallons of fuel was consumed by United airlines in 2018 ?', 'output': 'Based on the table information, the final answer is {\"answer\": \"4,137\"}.', 'task_type': 'TQA', 'dataset_name': 'AIT-QA', 'original_query': 'How many gallons of fuel was consumed by United airlines in 2018 ?', 'answer_list': ['4,137'], 'original_query_type': 'AIT-QA_Table-driven'}\n",
      "--------------------------------------------------\n",
      "PubHealthTab\n",
      "{'item_id': 'PubHealthTab_ad1f29a0-0546-40dc-8752-c3fa77984a4c', 'image_id': 'PubHealthTab_table_0', 'input': 'statement: More Democrats were represented in the table as of June 2021, than were Republicans in the same time frame..\\nReview the table from a website named \\'Illinois General Assembly - Ballotpedia\\' to determine if the statement is affirmed or refuted by the table. Use \\'neutral\\' for inconclusive evidence. Present the final answer in a JSON format {\"answer\": \"<YOUR ANSWER>\"} like {\"answer\": \"confirmed\"}.', 'output': 'Based on the table, the statement is true. So, the final answer is {\"answer\": \"affirmed\"}.', 'task_type': 'TFV', 'dataset_name': 'PubHealthTab', 'original_query': 'More Democrats were represented in the table as of June 2021, than were Republicans in the same time frame.', 'answer_list': ['affirmed'], 'original_query_type': 'PubHealthTab'}\n"
     ]
    }
   ],
   "source": [
    "for k in cnt.keys():\n",
    "    for item in data:\n",
    "       typ = item[\"original_query_type\"]\n",
    "       if typ == k:\n",
    "           print(\"-\" * 50)\n",
    "           print(k)\n",
    "           print(item)\n",
    "           break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-16T13:21:18.217727Z",
     "start_time": "2024-08-16T13:21:17.072222Z"
    }
   },
   "id": "1e97f34ae98bc989",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a6c119ddcf3b501"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
