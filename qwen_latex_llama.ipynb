{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "qwen_path = \"/bohr/cach-rxl3/v17/cache/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/51c47430f97dd7c74aa1fa6825e68a813478097f\"\n",
    "llama_path = \"/bohr/cach-rxl3/v15/cache/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/5206a32e0bd3067aef1ce90f5528ade7d866253f\"\n",
    "# os.system(f\"cp -r {raw_cache_path} .\")\n",
    "# os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "# os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "# os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "device = \"cuda\"\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "l2i = defaultdict(lambda: -1)\n",
    "for i, letter in enumerate('ABCDEFGH'):\n",
    "    l2i[letter] = i\n",
    "sub_list = ('Physics', 'Mathematics', 'ComputerScience', 'QuantitativeBiology', 'QuantitativeFinance',\n",
    "            'Statistics', 'ElectricalEngineeringandSystemsScience', 'Economics', '')\n",
    "IMAGE_FACTOR = 28\n",
    "MIN_PIXELS = 4 * 28 * 28\n",
    "MAX_PIXELS = 16384 * 28 * 28\n",
    "MAX_RATIO = 200\n",
    "\n",
    "\n",
    "def round_by_factor(number: int, factor: int) -> int:\n",
    "    \"\"\"Returns the closest integer to 'number' that is divisible by 'factor'.\"\"\"\n",
    "    return round(number / factor) * factor\n",
    "\n",
    "\n",
    "def ceil_by_factor(number: int, factor: int) -> int:\n",
    "    \"\"\"Returns the smallest integer greater than or equal to 'number' that is divisible by 'factor'.\"\"\"\n",
    "    return math.ceil(number / factor) * factor\n",
    "\n",
    "\n",
    "def floor_by_factor(number: int, factor: int) -> int:\n",
    "    \"\"\"Returns the largest integer less than or equal to 'number' that is divisible by 'factor'.\"\"\"\n",
    "    return math.floor(number / factor) * factor\n",
    "\n",
    "\n",
    "def smart_resize(\n",
    "        height: int, width: int, factor: int = IMAGE_FACTOR, min_pixels: int = MIN_PIXELS, max_pixels: int = MAX_PIXELS\n",
    "):\n",
    "    \"\"\"\n",
    "    Rescales the image so that the following conditions are met:\n",
    "\n",
    "    1. Both dimensions (height and width) are divisible by 'factor'.\n",
    "\n",
    "    2. The total number of pixels is within the range ['min_pixels', 'max_pixels'].\n",
    "\n",
    "    3. The aspect ratio of the image is maintained as closely as possible.\n",
    "    \"\"\"\n",
    "    if max(height, width) / min(height, width) > MAX_RATIO:\n",
    "        raise ValueError(\n",
    "            f\"absolute aspect ratio must be smaller than {MAX_RATIO}, got {max(height, width) / min(height, width)}\"\n",
    "        )\n",
    "    h_bar = max(factor, round_by_factor(height, factor))\n",
    "    w_bar = max(factor, round_by_factor(width, factor))\n",
    "    if h_bar * w_bar > max_pixels:\n",
    "        beta = math.sqrt((height * width) / max_pixels)\n",
    "        h_bar = floor_by_factor(height / beta, factor)\n",
    "        w_bar = floor_by_factor(width / beta, factor)\n",
    "    elif h_bar * w_bar < min_pixels:\n",
    "        beta = math.sqrt(min_pixels / (height * width))\n",
    "        h_bar = ceil_by_factor(height * beta, factor)\n",
    "        w_bar = ceil_by_factor(width * beta, factor)\n",
    "    return h_bar, w_bar\n",
    "\n",
    "\n",
    "def count_rows_cols(latex_code):\n",
    "    try:\n",
    "        # 查找列数：根据表格行的定义找到表格列标识符，如 |l|c|c|c|c|\n",
    "        columns = re.search(r'\\\\begin\\{tabular\\}\\{([^\\}]+)\\}', latex_code)\n",
    "        if columns:\n",
    "            num_cols = len([c for c in columns.group(1) if c.isalpha()])\n",
    "        else:\n",
    "            num_cols = 0\n",
    "\n",
    "        # 查找行数：根据 \\hline 分隔符统计表格的行数\n",
    "        rows = latex_code.split(r'\\\\')\n",
    "        num_rows = sum(1 for row in rows if '&' in row or '\\\\rule' in row)\n",
    "\n",
    "        return num_rows, num_cols\n",
    "    except:\n",
    "        return -1, -1\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "latex_data = []\n",
    "if os.environ.get('DATA_PATH_B'):\n",
    "    base_dir = os.environ.get('DATA_PATH_B')\n",
    "    with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        # data_t = list(json.load(f))[:100]\n",
    "else:\n",
    "    base_dir = '/bohr/form-recognition-train-b6y2/v4'\n",
    "    with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "        data = list(json.load(f))[:10]\n",
    "\n",
    "\n",
    "def generate_latex(llm, sampling_params, inputs, cnt):\n",
    "    outputs = llm.generate(inputs, sampling_params=sampling_params)\n",
    "    latex = [output.outputs[0].text for output in outputs]\n",
    "    for ii, l in enumerate(latex):\n",
    "        # print(l)\n",
    "        rows, cols = count_rows_cols(l)\n",
    "        idx = ii + cnt * batch_size\n",
    "        data[idx][\"latex\"] = l\n",
    "        data[idx][\"rows\"] = rows\n",
    "        data[idx][\"cols\"] = cols\n",
    "\n",
    "\n",
    "def preprocess():\n",
    "    llm = LLM(\n",
    "        model=qwen_path,\n",
    "        limit_mm_per_prompt={\"image\": 1},\n",
    "    )\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=0.0,\n",
    "        top_p=1,\n",
    "        repetition_penalty=1.05,\n",
    "        max_tokens=4096,\n",
    "        stop_token_ids=[],\n",
    "    )\n",
    "    # processor = AutoProcessor.from_pretrained(qwen_path)\n",
    "    # prompt = processor.apply_chat_template([\n",
    "    #     {\"role\": \"system\",\n",
    "    #      \"content\": \"You are a helpful assistant. Provide only latex code for the table in the image.\"},\n",
    "    #     {\"role\": \"user\", \"content\": [\n",
    "    #         {\"type\": \"image\", \"image\": \"\"},\n",
    "    #         {\"type\": \"text\", \"text\": \"Convert the table in the image to latex code.\"}\n",
    "    #     ]}\n",
    "    # ], tokenize=False, add_generation_prompt=True)\n",
    "    # # print(\"---------------------->> prompt\")\n",
    "    # # print(prompt)\n",
    "    prompt = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant. Provide only latex code for the table in the image.<|im_end|>\n",
    "<|im_start|>user\n",
    "<|vision_start|><|image_pad|><|vision_end|>Convert the table in the image to latex code.<|im_end|>\n",
    "<|im_start|>assistant\"\"\"\n",
    "    inputs = []\n",
    "    cnt = 0\n",
    "    for d in data:\n",
    "        r_path = os.path.join(base_dir, \"test_images\", d[\"image_path\"])\n",
    "        img = fetch_image_path(r_path)\n",
    "        input = {\n",
    "            \"prompt\": prompt,\n",
    "            \"multi_modal_data\": {\n",
    "                \"image\": img\n",
    "            }\n",
    "        }\n",
    "        inputs.append(input)\n",
    "        if len(inputs) == batch_size:\n",
    "            generate_latex(llm, sampling_params, inputs, cnt)\n",
    "            cnt += 1\n",
    "            inputs = []\n",
    "    if len(inputs) > 0:\n",
    "        generate_latex(llm, sampling_params, inputs, cnt)\n",
    "\n",
    "\n",
    "def process():\n",
    "    llm = LLM(model=llama_path)\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=0.0,\n",
    "        top_p=1,\n",
    "        repetition_penalty=1.05,\n",
    "        max_tokens=2,\n",
    "        stop_token_ids=[],\n",
    "    )\n",
    "\n",
    "    #     processor = AutoProcessor.from_pretrained(llama_path)\n",
    "    #\n",
    "    #     \"\"\"\n",
    "    #     <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    # Cutting Knowledge Date: December 2023\n",
    "    # Today Date: 26 Jul 2024\n",
    "    # sys2<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    # q2<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    #     \"\"\"\n",
    "\n",
    "    q_prefix = \"Based on the latex table, \"\n",
    "    inputs = []\n",
    "    cnt = 0\n",
    "    for d in data:\n",
    "        q0 = f'\"{d[\"latex\"]}\" This is latex code for a table. The caption of the table is \"{d[\"caption\"]}\".'\n",
    "        q2 = f\"\"\"{q0}{q_prefix}which subject is most relevant to the table or caption?\n",
    "A) Physics\n",
    "B) Mathematics\n",
    "C) Computer Science\n",
    "D) Quantitative Biology\n",
    "E) Quantitative Finance\n",
    "F) Statistics\n",
    "G) Electrical Engineering and Systems Science\n",
    "H) Economics\n",
    "Provide only the label [A-H] of the best answer for multiple-choice question without extra explanation (just a letter).\n",
    "\"\"\"\n",
    "        question = d[\"question\"]\n",
    "        question = question[0].lower() + question[1:]\n",
    "        q3 = f\"\"\"{q0}{q_prefix}{question}\n",
    "A) {d[\"options\"][0]}\n",
    "B) {d[\"options\"][1]}\n",
    "C) {d[\"options\"][2]}\n",
    "D) {d[\"options\"][3]}\n",
    "Provide only the label [A-D] of the correct best for multiple-choice question without extra explanation (just a letter).\n",
    "\"\"\"\n",
    "        inputs.append(q2)\n",
    "        inputs.append(q3)\n",
    "        if len(inputs) == 2 * batch_size:\n",
    "            generate_ans(llm, sampling_params, inputs, cnt)\n",
    "            cnt += 1\n",
    "            inputs = []\n",
    "    if len(inputs) > 0:\n",
    "        generate_ans(llm, sampling_params, inputs, cnt)\n",
    "\n",
    "\n",
    "def generate_ans(llm, sampling_params, inputs, cnt):\n",
    "    outputs = llm.generate(inputs, sampling_params=sampling_params)\n",
    "    outputs = [output.outputs[0].text for output in outputs]\n",
    "    l = len(outputs) // 2\n",
    "    # print(\"-->> ans\")\n",
    "    # print(outputs)\n",
    "    for i in range(l):\n",
    "        idx = cnt * batch_size + i\n",
    "\n",
    "        data[idx][\"subject\"] = outputs[2 * i]\n",
    "        data[idx][\"option\"] = outputs[2 * i + 1]\n",
    "\n",
    "\n",
    "def postprocess():\n",
    "    submission = []\n",
    "    for d in data:\n",
    "        subject = d[\"subject\"]\n",
    "        option = d[\"option\"]\n",
    "        category = \"\"\n",
    "        answer = -1\n",
    "        try:\n",
    "            match = re.search(r'[A-Za-z]', subject)\n",
    "            if match:\n",
    "                category = match.group(0).upper()\n",
    "                category = sub_list[l2i[category]]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            match = re.search(r'[A-Za-z]', option)\n",
    "            if match:\n",
    "                answer = match.group(0).upper()\n",
    "                answer = l2i[answer]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        sub_item = {\n",
    "            \"image_path\": d[\"image_path\"],\n",
    "            \"category\": category,\n",
    "            \"cols\": d[\"cols\"],\n",
    "            \"rows\": d[\"rows\"],\n",
    "            \"answer\": answer,\n",
    "        }\n",
    "        # print(sub_item)\n",
    "        submission.append(sub_item)\n",
    "    if len(submission) != 5360:\n",
    "        with open('error.json', 'w') as f:\n",
    "            json.dump(submission, f)\n",
    "        raise Exception(f\"Submission length is {len(submission)}\")\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump(submission, f)\n",
    "\n",
    "\n",
    "def fetch_image_path(img_path, size_factor: int = IMAGE_FACTOR) -> Image.Image:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    width, height = img.size\n",
    "    resized_height, resized_width = smart_resize(\n",
    "        height,\n",
    "        width,\n",
    "        factor=size_factor,\n",
    "        min_pixels=MIN_PIXELS,\n",
    "        max_pixels=MAX_PIXELS,\n",
    "    )\n",
    "    img = img.resize((resized_width, resized_height))\n",
    "    return img\n",
    "\n",
    "\n",
    "preprocess()\n",
    "process()\n",
    "postprocess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
