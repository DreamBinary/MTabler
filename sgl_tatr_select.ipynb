{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "q_prefix = \"Based on the table, caption and html structure, \"\n",
    "\n",
    "\n",
    "def rewrite():\n",
    "    import os\n",
    "    import json\n",
    "    NEW_IMG_DIR = \"new_images\"\n",
    "    os.makedirs(NEW_IMG_DIR, exist_ok=True)\n",
    "    if os.environ.get('DATA_PATH_B'):\n",
    "        base_dir = os.environ.get('DATA_PATH_B')\n",
    "        with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "            data_t = json.load(f)\n",
    "            data_t = list(json.load(f))[:10]\n",
    "    else:\n",
    "        base_dir = '/bohr/form-recognition-train-b6y2/v4'\n",
    "        with open(os.path.join(base_dir, 'dataset.json'), 'r') as f:\n",
    "            data_t = list(json.load(f))[:10]\n",
    "    data = []\n",
    "    for d in data_t:\n",
    "        r_path = os.path.join(base_dir, \"test_images\", d[\"image_path\"])\n",
    "        w_path = os.path.join(NEW_IMG_DIR, d[\"image_path\"])\n",
    "        question = d[\"question\"]\n",
    "        question = question[0].lower() + question[1:]\n",
    "        q3 = f\"{q_prefix}{question}\"\n",
    "        data.append({\n",
    "            \"r_path\": r_path,\n",
    "            \"w_path\": w_path,\n",
    "            \"image_path\": d[\"image_path\"],\n",
    "            \"caption\": d[\"caption\"],\n",
    "            \"q3\": q3,\n",
    "            \"options\": [\n",
    "                f'A) {d[\"options\"][0]}',\n",
    "                f'B) {d[\"options\"][1]}',\n",
    "                f'C) {d[\"options\"][2]}',\n",
    "                f'D) {d[\"options\"][3]}'\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    with open('data.json', 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "# multiprocessing.log_to_stderr(logging.INFO)\n",
    "# logger = multiprocessing.get_logger()\n",
    "# logging.basicConfig(filename='sgl_unitable4.log', level=logging.INFO)\n",
    "\n",
    "p = multiprocessing.Process(target=rewrite)\n",
    "p.start()\n",
    "\n",
    "pkgs_path = \"/bohr/pkgs-7x29/v18/pkgs\"\n",
    "opkgs_path = \"/bohr/opkgs-k2wz/v1/opkgs\"\n",
    "model_path = \"lmms-lab/llava-onevision-qwen2-7b-si\"\n",
    "cache_path = \"/bohr/cach-rxl3/v9/cache\"\n",
    "torch_hub_path = \"/bohr/thub-w4uy/v1\"\n",
    "tatr_path = \"/bohr/tatr-xdh6/v1/tatr\"\n",
    "str_model_path = '/bohr/TATR-xmup/v1/TATR/TATR-v1.1-All-msft.pth'\n",
    "str_config_path = '/bohr/TATR-xmup/v1/TATR/structure_config.json'\n",
    "os.system(\"pip uninstall psutil -y\")\n",
    "os.system(f\"pip3 install {pkgs_path}/* --ignore-installed\")\n",
    "os.system(f\"pip3 install {opkgs_path}/*\")\n",
    "os.system(f\"cp -r {tatr_path} .\")\n",
    "# # 提交时可能不能联网，设置成离线模式防止联网失败报错\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_path\n",
    "os.environ[\"HF_HOME\"] = cache_path\n",
    "os.environ[\"TORCH_HOME\"] = torch_hub_path\n",
    "device = \"cuda\"\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "from collections import defaultdict\n",
    "from sglang.lang.chat_template import get_chat_template\n",
    "from PIL import Image\n",
    "import json\n",
    "from sglang import Runtime\n",
    "import warnings\n",
    "import sglang as sgl\n",
    "import torch\n",
    "import multiprocessing\n",
    "import re\n",
    "from tatr import TableEngine\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "l2i = defaultdict(lambda: -1)\n",
    "for i, letter in enumerate('ABCDEFGH'):\n",
    "    l2i[letter] = i\n",
    "sub_list = ('Physics', 'Mathematics', 'ComputerScience', 'QuantitativeBiology', 'QuantitativeFinance',\n",
    "            'Statistics', 'ElectricalEngineeringandSystemsScience', 'Economics', '')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "q2 = f\"\"\"{q_prefix}which subject is most relevant to the table or caption?\"\"\"\n",
    "\n",
    "\n",
    "@sgl.function\n",
    "def one_image(s, path, q1, q3, options):\n",
    "    s += sgl.system(\n",
    "        \"You are a helpful assistant. Provide only an label ([A-H] or [A-D]) of the correct answer for multiple-choice questions.\")\n",
    "    s += sgl.user(sgl.image(path) + q1)\n",
    "    s += sgl.assistant(\"I have a general understanding of the information in this table.\")\n",
    "    s += sgl.user(q2)\n",
    "    s += sgl.assistant(\n",
    "        sgl.select(\n",
    "            \"subject\",\n",
    "            choices=[\n",
    "                \"A) Physics\",\n",
    "                \"B) Mathematics\",\n",
    "                \"C) Computer Science\",\n",
    "                \"D) Quantitative Biology\",\n",
    "                \"E) Quantitative Finance\",\n",
    "                \"F) Statistics\",\n",
    "                \"G) Electrical Engineering and Systems Science\",\n",
    "                \"H) Economics\",\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "    )\n",
    "    s += sgl.user(q3)\n",
    "    s += sgl.assistant(\n",
    "        sgl.select(\n",
    "            \"option\",\n",
    "            choices=options,\n",
    "            temperature=0.0\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_out(o, s):\n",
    "    img_path, rows, cols = o\n",
    "    category = \"\"\n",
    "    answer = -1\n",
    "    try:\n",
    "        subject = s[\"subject\"]\n",
    "        match = re.search(r'[A-Za-z]', subject)\n",
    "        if match:\n",
    "            category = match.group(0).upper()\n",
    "            category = sub_list[l2i[category]]\n",
    "    except:\n",
    "        category = \"\"\n",
    "    try:\n",
    "        option = s[\"option\"]\n",
    "        match = re.search(r'[A-Za-z]', option)\n",
    "        if match:\n",
    "            answer = match.group(0).upper()\n",
    "            answer = l2i[answer]\n",
    "    except:\n",
    "        answer = -1\n",
    "    sub_item = {\n",
    "        \"image_path\": img_path,\n",
    "        \"category\": category,\n",
    "        \"cols\": cols,\n",
    "        \"rows\": rows,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "    return sub_item\n",
    "\n",
    "\n",
    "class Worker:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 8\n",
    "        self.ocr_data = multiprocessing.Queue()\n",
    "\n",
    "    def run(self):\n",
    "        ocr_process = multiprocessing.Process(target=self.ocr)\n",
    "        ocr_process.start()\n",
    "\n",
    "        model_overide_args = {\n",
    "            \"attn_implementation\": \"eager\",\n",
    "            \"multimodal\": True,\n",
    "            \"overwrite_config\": {\n",
    "                \"image_aspect_ratio\": \"anyres_max_9\"\n",
    "            },\n",
    "        }\n",
    "        runtime = Runtime(\n",
    "            model_path=model_path,\n",
    "            model_overide_args=model_overide_args,\n",
    "            # disable_regex_jump_forward=True,\n",
    "            # # enable_mixed_chunk=True,\n",
    "            # triton_attention_reduce_in_fp32=True,\n",
    "        )\n",
    "        runtime.endpoint.chat_template = get_chat_template(\"qwen\")\n",
    "        sgl.set_default_backend(runtime)\n",
    "\n",
    "        # post = multiprocessing.Process(target=self.post_process)\n",
    "        # post.start()\n",
    "\n",
    "        self.process()\n",
    "        runtime.shutdown()\n",
    "        # post.join()\n",
    "\n",
    "    def ocr(self):\n",
    "        engine = TableEngine(\n",
    "            str_device=device,\n",
    "            str_model_path=str_model_path,\n",
    "            str_config_path=str_config_path\n",
    "        )\n",
    "        outputs = []\n",
    "        inputs = []\n",
    "        with open('data.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "        for item in data:\n",
    "            img = Image.open(item[\"r_path\"])\n",
    "            html, rows, cols = engine(img, item[\"w_path\"], tokens=[])\n",
    "            q1 = f'This is a table image. The caption of the table is \"{item[\"caption\"]}\". The structure of the table in html format is as follows: {html}.'\n",
    "            outputs.append((item[\"image_path\"], rows, cols))\n",
    "            inputs.append({\"path\": item[\"r_path\"], \"q1\": q1, \"q3\": item[\"q3\"], \"options\": item[\"options\"]})\n",
    "            if len(outputs) == self.batch_size:\n",
    "                self.ocr_data.put((outputs, inputs))\n",
    "                outputs, inputs = [], []\n",
    "        if outputs:\n",
    "            self.ocr_data.put((outputs, inputs))\n",
    "        self.ocr_data.put(None)\n",
    "\n",
    "    def process(self):\n",
    "        flag = True\n",
    "        submission = []\n",
    "        while flag:\n",
    "            try:\n",
    "                item = self.ocr_data.get(timeout=300)\n",
    "                if item is None:\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            outputs, inputs = item\n",
    "            states = one_image.run_batch(inputs)\n",
    "            for o, s in zip(outputs, states):\n",
    "                sub_item = clean_out(o, s)\n",
    "                submission.append(sub_item)\n",
    "        if len(submission) != 5360:\n",
    "            import sys\n",
    "            sys.exit(f\"Submission length is {len(submission)}\")\n",
    "        with open('submission.json', 'w') as f:\n",
    "            json.dump(submission, f)\n",
    "\n",
    "\n",
    "p.join()\n",
    "worker = Worker()\n",
    "worker.run()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e447f78f697a3d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
